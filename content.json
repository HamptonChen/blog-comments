{"meta":{"title":"代码视界","subtitle":"Hampton Chen's Blog","description":null,"author":"Hampton Chen","url":"http://www.chenhanpeng.com","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2019-03-20T08:33:13.864Z","updated":"2019-03-20T08:33:13.864Z","comments":false,"path":"/404.html","permalink":"http://www.chenhanpeng.com//404.html","excerpt":"","text":""},{"title":"关于自己","date":"2019-06-04T15:12:16.068Z","updated":"2019-06-04T15:12:16.068Z","comments":false,"path":"about/index.html","permalink":"http://www.chenhanpeng.com/about/index.html","excerpt":"","text":"Personal一个喜欢瞎折腾的程序猿，干着前端的工作，向往着AI、大数据领域。 Blog本博客主要记录和分享一些平时学习或看到的知识，如有错误之处烦请指正。博客内容主要集中在前端、机器学习和大数据领域，但不局限于此。 ContactEmail: chenhp1994@163.com"},{"title":"archives","date":"2019-03-19T15:35:45.000Z","updated":"2019-03-19T15:35:45.761Z","comments":true,"path":"archives/index.html","permalink":"http://www.chenhanpeng.com/archives/index.html","excerpt":"","text":""},{"title":"书单","date":"2019-03-20T08:33:13.869Z","updated":"2019-03-20T08:33:13.869Z","comments":false,"path":"books/index.html","permalink":"http://www.chenhanpeng.com/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2019-03-20T08:33:13.870Z","updated":"2019-03-20T08:33:13.870Z","comments":false,"path":"categories/index.html","permalink":"http://www.chenhanpeng.com/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2019-03-20T08:33:13.872Z","updated":"2019-03-20T08:33:13.872Z","comments":true,"path":"links/index.html","permalink":"http://www.chenhanpeng.com/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2019-03-20T08:33:13.873Z","updated":"2019-03-20T08:33:13.873Z","comments":false,"path":"repository/index.html","permalink":"http://www.chenhanpeng.com/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-03-20T08:33:13.875Z","updated":"2019-03-20T08:33:13.875Z","comments":false,"path":"tags/index.html","permalink":"http://www.chenhanpeng.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Python从小白到攻城狮(10)——高阶函数","slug":"python_series/python_10_高阶函数","date":"2019-09-22T13:28:53.000Z","updated":"2019-09-22T13:36:16.030Z","comments":true,"path":"2019/09/22/python_series/python_10_高阶函数/","link":"","permalink":"http://www.chenhanpeng.com/2019/09/22/python_series/python_10_高阶函数/","excerpt":"","text":"本节将主要介绍什么是高阶函数、高阶函数的用法以及Python的几个常见的内置高阶函数。 什么是高阶函数高阶函数(Higher-order function)：一个函数可以作为参数传给另一个函数，或者一个函数的返回值为另一个函数（若返回值为该函数本身，则为递归），满足其一则为高阶函数。 下面，我们通过例子来进一步学习高阶函数的用法。 参数为函数12345678910111213# 参数为函数def print_hello(): print('hello world')def print_function(func): func() print('in the print_function')print_function(print_hello)########输出结果######hello worldin the print_function 在上面的代码中，我们将print_hello()函数作为参数func传递给print_function()函数，直接调用print_hello()和调用func()结果一样。 返回值为函数1234567891011121314# 返回值为函数def print_hello(): print('hello world')def print_function(): print('in the print_func') return print_helloresult = print_function()result()#####输出#####in the print_funchello world 上面的例子中，print_hello()函数作为print_function()的返回值。 备注：函数名(print_hello、print_function)–&gt;其为该函数的内存地址；函数名+括号(print_hello())–&gt;调用该函数。 Python内置的高阶函数map()、filter()、reduce()、sorted()，这几个均为Python内置的高阶函数。通常结合匿名函数lambda一起使用。接下来我们看一下这三个函数的用法以及其内部原理。 map(function, iterable)函数：map函数接收的是两个参数：一个函数，一个Iterable。map对iterable中的每个元素，都运用function这个函数，最后返回一个新的Iterable，即迭代器对象，例如：&lt;map object at 0x00000214EEF40BA8&gt;。 比如：要对列表中的每个元素乘以2，用map可以实现如下：123l = [1, 2, 3, 4, 5]re = map(lambda x: x * 2, l)print(list(re)) # [2， 4， 6， 8， 10] filter(function, iterable)函数filter函数和map函数类似，也是接收一个函数和一个序列的高阶函数，主要功能是过滤。 filter()函数表示对iterable中的每个元素，都是用function判断，并返回True或False，最后将返回True的元素组成一个迭代器对象，其返回值也是迭代器对象，例如：&lt;filter object at 0x000002042D25EA90&gt;。 注意到filter()函数返回的是一个Iterator，也就是一个惰性序列，所以要强迫filter()完成计算结果，需要用list()函数获得所有结果并返回list。 比如：我们要返回一个列表中的所有奇数：123l = [1, 2, 3, 4, 5]result = filter(lambda x: x % 2 == 1, l)print(list(result)) #[1, 3, 5] reduce(function, iterable)函数这里的function同样是一个函数对象，规定它有两个参数，表示对iterable中的每个元素及上一次调用的结果，运用function进行计算，所以最后返回的是一个单独的数值。 例子：计算某个列表元素的乘积。12345from functools import reducel2 = [1, 2, 3, 4, 5]result = reduce(lambda x, y: x * y, l2)print(result) # 1*2*3*4*5=120 python3中reduce函数被取消了，放入到了functools模块中，所以在语句前加上一条：from functools import reduce sorted()函数sorted() 函数对所有可迭代的对象进行排序操作。 sort 与 sorted 区别： sort 是应用在 list 上的方法，sorted 可以对所有可迭代的对象进行排序操作。 list 的 sort 方法返回的是对已经存在的列表进行操作，而内建函数 sorted 方法返回的是一个新的 list，而不是在原来的基础上进行的操作。 sorted语法：sorted(iterable, key=None, reverse=False) 参数说明： iterable：可迭代对象 key：主要用来进行比较的元素，只有一个参数，具体的函数的参数就是取自于可迭代对象中，指定可迭代对象中的一个元素来进行排序。 reverse：排序规则，reverse=True 降序，reverse=False 升序（默认）。 返回值返回重新排序的列表 示例1234567891011a = [1, 5, 3, 6, 9, 8]b = sorted(a)print(a) # [1, 5, 3, 6, 9, 8]print(b) # [1, 3, 5, 6, 8, 9]l = [('b', 2), ('a', 1), ('c', 3), ('d', 4)]l1 = sorted(l, key=lambda s:s[1])print(l1) # [('a', 1), ('b', 2), ('c', 3), ('d', 4)]l2 = sorted(l, key=lambda s:s[1], reverse=True) # 降序print(l2) # [('d', 4), ('c', 3), ('b', 2), ('a', 1)] 文中示例代码： python-learning 未完待续，持续更新中……","categories":[{"name":"Python","slug":"Python","permalink":"http://www.chenhanpeng.com/categories/Python/"}],"tags":[{"name":"python教程","slug":"python教程","permalink":"http://www.chenhanpeng.com/tags/python教程/"},{"name":"高阶函数","slug":"高阶函数","permalink":"http://www.chenhanpeng.com/tags/高阶函数/"}]},{"title":"Python从小白到攻城狮(9)——匿名函数","slug":"python_series/python_9_匿名函数","date":"2019-09-18T04:00:13.000Z","updated":"2019-09-18T12:21:38.238Z","comments":true,"path":"2019/09/18/python_series/python_9_匿名函数/","link":"","permalink":"http://www.chenhanpeng.com/2019/09/18/python_series/python_9_匿名函数/","excerpt":"","text":"在前面函数那节中，我们一起学习了Python的常规函数。但是在代码中，除了常规函数，我们也会见到一些“非常规”函数，它们往往很简短，就一行，并且有个很酷炫的名字——lambda，这就是匿名函数。 什么是匿名函数所谓匿名，即不再使用def语句这样标准的形式定义一个函数。 lambda只是一个表达式，函数体比def简单得多。 lambda的主题是一个表达式，而不是一个代码块，仅仅能在lambda表达式中封装有限的逻辑进去。 lambda函数拥有自己的命名空间，且不能访问自己参数列表之外或全局命名空间里的参数。 虽然lambda函数看起来只有一行，却不等同于C或C++的内联函数，后者的目的是调用小函数时不占用栈内存从而增加运行效率。 语法lambda函数的语法只包含一个语句，如下：1lambda argument1, argument2,... argumentN : expression 从上面的语法我们可以看到，匿名函数的关键字是lambda，之后是一系列的参数，用冒号隔开，最后则是由这些参数组成的表达式。 我们通过几个例子来看下它的用法：12345square = lambda x: x**2print(square(5))sum = lambda x, y: x + yprint(sum(2, 3)) 可以看到，匿名函数lambda和常规函数一样，返回的都是一个函数对象(function object)，它们的用法也极其相似，不过有下面几点区别： 匿名函数和常规函数区别第一，lambda是一个表达式(expression)，而不是一个语句(statement)。 所谓的表达式，就是用一系列“公式”去表达一个东西，比如 x+y 、 x**2等等。 所谓的语句，则一定是完成了某些功能，比如赋值语句 x = 2完成了赋值，print语句print(x) 完成了打印等等。 因此，lambda可以用在一些常规函数def不能用的地方，比如，lambda可以用在列表内部，而常规函数却不能：12l = [(lambda x: x*x)(x) for in range(10)]print(l) 再比如，lambda可以被用作某些函数的参数，而常规函数def也不能：123l = [(1, 20), (3, 10), (5, 25), (2, 0)]l.sort(key=lambda x: x[1]) # 按照列表中元组的第二个元素排序print(l) 常规函数def必须通过其函数名被调用，因此必须首先被定义。但是作为一个表达式的lambda，返回的函数对象就不需要名字了。 第二，lambda的主体是只有一行的简单表达式，并不能扩展成一个多行的代码块。这其实是出于设计的考虑。Python之所以发明lambda，就是为了让它和常规函数各司其职：lambda专注于简单的任务，而常规函数则负责更复杂的多行逻辑。 用匿名函数改造下面的代码：1234567def is_odd(n): return n % 2 == 1L = list(filter(is_odd, range(1, 10)))# lambda改造new_l = list(filter(lambda x: x % 2 == 1, range(1, 10))) 总结这一节，我们一起学习了Python中的匿名函数lambda，它的主要用途是减少代码的复杂度。需要注意的是lambda是一个表达式，并不是一个语句；它只能写成一行的表达形式，语法上并不支持多行。匿名函数通常的使用场景是：程序中需要使用一个函数完成一个简单的功能，并且该函数只调用一次。 文中示例代码： python-learning 未完待续，持续更新中……","categories":[{"name":"Python","slug":"Python","permalink":"http://www.chenhanpeng.com/categories/Python/"}],"tags":[{"name":"python教程","slug":"python教程","permalink":"http://www.chenhanpeng.com/tags/python教程/"}]},{"title":"Python从小白到攻城狮(8)——模块","slug":"python_series/python_8_模块","date":"2019-09-05T15:00:13.000Z","updated":"2019-09-18T12:21:01.200Z","comments":true,"path":"2019/09/05/python_series/python_8_模块/","link":"","permalink":"http://www.chenhanpeng.com/2019/09/05/python_series/python_8_模块/","excerpt":"","text":"随着程序代码越写越多，一个文件中的代码越来越长，也越来越难以维护。为了编写可维护的代码，我们把很多函数分组，放到不同的文件中，这样每个文件包含的代码相对较少。 在Python中，一个.py文件就称为一个模块(Module)，里面定义了一些函数、类和变量，也可能包含可执行的代码。 模块让你能够有逻辑地组织你的 Python 代码段。把相关的代码分配到一个模块里能让你的代码更好用，更易懂。 模块 从上面我们知道了模块就是一个.py文件，接下来我们来看下如何定义和引用一个模块。 如何定义一个模块下面是简单的模块hello.py:12def print_hello(): print('hello world!') import 语句定义好模块后，我们可以使用import语句来引入模块，语法如下：1import module1[, module2[,... moduleN]] 当解释器遇到import语句，如果模块在当前的搜索路径就会被导入。 调用的时候使用函数名.方法名来进行调用。 我们新建一个test_hello.py文件来调用hello.py模块的方法。123import hellohello.print_hello() 不管你执行多少次import，一个模块只会被导入一次。这样可以防止导入模块被一遍又一遍地执行。 from…import语句Python的from语句让你从模块中导入一个指定的部分到当前命名空间中。语法如下1from module import name1[, name2[, ... nameN]] 例如，我们要导入hello.py模块中的print_hello方法，使用如下语句：1from hello import print_hello 这个声明不会把整个 hello 模块导入到当前的命名空间中，它只会将 hello 里的 print_hello 单个引入到执行这个声明的模块的全局符号表。 from…import* 语句把一个模块的所有内容全都导入到当前的命名空间也是可行的，只需使用如下声明：1from modname import * 这提供了一个简单的方法来导入一个模块中的所有项目。然而这种声明不该被过多地使用。 Python中的包 包是一个分层次的文件目录结构，它定义了一个由模块及子包，和子包下的子包等组成的Python的应用环境。 简单来说，包就是文件夹，但该文件夹下必须存在init.py文件，该文件的内容可以为空。init.py用于标识当前文件夹是一个包。 示例：我们创建一个test包，目录结构如下：123test -- __init__.py -- test_cal.py test_cal.py模块的代码如下：12345def add(x, y): return x + ydef square(x): return x * x 包的使用Python包的使用和模块的使用类似，可以通过import语句和from…import语句导入。 新建一个do.py来导入和使用test包，我们先用import语句导入：12import test.test_calprint(test.test_cal.add(10, 20)) 如果包含多层子包，那么调用方法前面还有写一长串的包名，特别不方便，我们可以用from…import语句来简化：12from test.test_cal import squareprint(square(10)) 文中示例代码： python-learning 未完待续，持续更新中…… 参考：https://www.runoob.com/python/python-modules.html","categories":[{"name":"Python","slug":"Python","permalink":"http://www.chenhanpeng.com/categories/Python/"}],"tags":[{"name":"python教程","slug":"python教程","permalink":"http://www.chenhanpeng.com/tags/python教程/"},{"name":"模块","slug":"模块","permalink":"http://www.chenhanpeng.com/tags/模块/"}],"author":"陈汉鹏"},{"title":"Python从小白到攻城狮(7)——函数","slug":"python_series/python_7_函数","date":"2019-09-05T07:55:35.000Z","updated":"2019-09-18T11:54:07.634Z","comments":true,"path":"2019/09/05/python_series/python_7_函数/","link":"","permalink":"http://www.chenhanpeng.com/2019/09/05/python_series/python_7_函数/","excerpt":"","text":"什么是函数 函数是组织好的，可复用的，用来实现单一，或相关联功能的代码段。 函数能提高应用的模块性和代码的复用率。在编程中，常将一些常用的功能写成函数放在函数库中供公共选用。利用好函数，可以减少我们重复编码的工作。 在前面学习中，我们用过许多Python的内置函数，比如print()、sort()等。 如何定义一个函数 根据下面的几个规则，我们可以定义一个函数： 函数代码块以def关键词开头，后接函数标识符名称和圆括号()。 任何传入参数和自变量必须放在圆括号中。圆括号之间可以用于定义参数。 函数的第一行语句可以选择性地使用文档字符串——用于存放函数说明。 函数内容以冒号起始，并且缩进。 return [表达式] 结束函数，选择性地返回一个值给调用方。不带表达式的return相当于返回None。也可以不返回。 语法123def function_name(parameters): 函数体 return [表达式] 默认情况下，参数值和参数名称是按函数声明中定义的顺序匹配起来的。 简单的示例 1234567891011# 定义一个简单的函数def print_str(): print('hello world!')print_str()# 定义一个带参数的函数def print_string(str): print(str)print_string('Hello World!!!!') 返回多个值 Python的函数支持返回多个值，我们通过下面的例子来了解其用法：12345678# 返回多个值def test(x, y): x1 = x + 2 y1 = y + 3 return x1, y1x, y = test(10, 20)print(x, y) 函数的参数 调用函数时可使用的正式参数类型有以下4种：必备参数、关键字参数、默认参数、不定长参数。 必备参数必备参数要以正确的顺序传入函数，调用时的数量必须和声明时的一样。 下面例子中的print_necessary_params()函数，调用时必须传入一个参数，不然会出现语法错误。12345678910def print_necessary_params(str1): print(str1)print_necessary_params()######控制台输出Traceback (most recent call last): File \"function.py\", line 28, in &lt;module&gt; print_necessary_params()TypeError: print_necessary_params() missing 1 required positional argument: 'str1' 关键字参数关键字参数和函数调用关系紧密，函数调用使用关键字参数来确定传入的参数值。 使用关键字参数允许函数调用时参数的顺序与声明时不一致，因为 Python 解释器能够用参数名匹配参数值。12345def print_keyword_params(id, price): print('id:', id) print('price', price)print_keyword_params(price=20, id=125345) 默认参数调用函数时，默认参数的值如果没有传入，则被认为是默认值。12345def print_default_param(price = 50): print(price)print_default_param()print_default_param(20) 不定长参数你可能需要一个函数能处理比当初声明时更多的参数。这些参数叫做不定长参数，和上述2种参数不同，声明时不会命名。基本语法如下：1234def functionname([formal_args,] *var_args_tuple ): \"函数_文档字符串\" function_suite return [expression] 加了星号（*）的变量名会存放所有未命名的变量参数。不定长参数实例如下：1234567def print_info(arg1, *params): print('arg1:', arg1) for var in params: print(var)print_info('test')print_info(10, 20, 30, 40) 递归函数 有时候我们需要反复调用某个函数得到一个最后的值，这个时候使用递归函数是最好的解决方案。 编程语言中，函数Func(Type a,……)直接或间接调用函数本身，则该函数称为递归函数。递归函数不能定义为内联函数。 举个例子，我们来计算阶乘n! = 1 x 2 x 3 x … x n，用函数fact(n)表示，可以看出： fact(n) = n! = 1 x 2 x 3 x … x (n-1) x n = (n-1)! x n = fact(n-1) x n 所以，fact(n)可以表示为n x fact(n-1)，只有n=1时需要特殊处理。 于是，fact(n)用递归的方式写出来就是：1234567def fact(n): if n==1: return 1 return n * fact(n - 1)print(fact(5))print(fact(10)) 总结本节介绍了Python函数的定义，不同类型的参数的使用以及递归函数的用法。 文中示例代码： python-learning 未完待续，持续更新中…… 参考：https://www.runoob.com/python/python-functions.htmlhttps://www.liaoxuefeng.com/wiki/1016959663602400/1017268131039072http://www.ityouknow.com/python/2019/08/08/python-005.html","categories":[{"name":"Python","slug":"Python","permalink":"http://www.chenhanpeng.com/categories/Python/"}],"tags":[{"name":"python教程","slug":"python教程","permalink":"http://www.chenhanpeng.com/tags/python教程/"},{"name":"函数","slug":"函数","permalink":"http://www.chenhanpeng.com/tags/函数/"}]},{"title":"Python从小白到攻城狮(6)——条件与循环","slug":"python_series/python_6_条件与循环","date":"2019-08-27T06:12:08.000Z","updated":"2019-09-18T12:22:46.283Z","comments":true,"path":"2019/08/27/python_series/python_6_条件与循环/","link":"","permalink":"http://www.chenhanpeng.com/2019/08/27/python_series/python_6_条件与循环/","excerpt":"","text":"在前面几篇文章中，我们学习了列表、元组、字典、集合和字符串等一系列Python的基本数据类型和数据结构。但仅靠这些数据结构类型是无法支持整个程序运行的，在编程中，流程控制是程序运行的基础，它决定了程序按照什么方式去执行。 接下来给大家介绍Python流程控制相关语法。 条件语句 Python的条件语句和其他语言一样，都是用if语句实现。 if语句表示如果发生什么样的条件，执行什么样的逻辑。 语法如下：123456789if condition_1: statement_1elif condition_2: statement_2...elif condition_i: statement_ielse: statement_n 示例：1234567id = 1if id == 0: print('red')elif id == 1: print('blue')else: print('yellow') 由于Python不支持switch语句，因此，当存在多个条件判断时，我们需要用else if来实现，这在Python中的表达是 elif。在条件语句中，可能会有零到多个elif部分，else是可选的。关键字 ‘elif’ 是 ‘else if’ 的缩写，这个可以有效地避免过深的缩进。 整个条件语句是顺序执行的，如果遇到一个条件满足，比如condition_i满足时，再执行完statement_i后，便会退出整个条件语句，而不会继续向下执行。 需要注意的是： 在条件语句末尾必须加上冒号(:)，这是Python特定的语法规范。 if语句可以单独使用，但elif、else都必须和if成对使用。 循环语句循环，本质上就是遍历集合中的元素。和其他语言一样，python中的循环一般通过for循环和while循环实现。 for循环语法格式如下：123456'''for 后面跟变量名，in后面跟序列（主要指列表、元组、字符串、文件等等）for 循环每次从序列中取一个值放到变量中'''for item in &lt;iterable&gt;: statements(s) 示例：1234567s = 'hello world'for char in s: print(char)list = [1, 2, 3, 4, 5]for item in list: print(item) 我们也可以通过索引来遍历元素。通常通过range()函数拿到索引，再去遍历访问元素。 12# 生成一个等差级数链表range (start， end， scan): 参数含义： start：计数从start开始，默认从0开始。比如range(3)等价于range(0, 3) end：计数到end结束，但不包括end。比如range(0, 3)的结果是[0, 1, 2]，但不包含3 scan：每次跳跃的间距，默认为1。 示例如下： 1234# 通过range()函数获取索引，再去遍历l = ['zhangsan', 'lisi', 'wangwu', 'sunliu', 'zhouqi']for index in range(0, len(l)): print(l[index]) 如果我们同时需要索引和元素时，可以通过Python内置的enumerate()函数来遍历集合。123# enumerate()函数来遍历集合for index, item in enumerate(l): print('index: &#123;&#125;, value: &#123;&#125;'.format(index, item)) 这里单独强调一下字典。字典本身只有键是可迭代的，如果我们要遍历它的值或者键值对，需要通过其内置的函数values()或items()实现。其中，values()返回字典的值的集合，items()返回键值对的集合。 12345678910111213d = &#123;'name': 'jack', 'age': 20, 'gender': 'male'&#125;# 遍历字典的键for k in d: print(k)# 遍历字典的值for val in d.values(): print(val)# 遍历字典的键值对for k, v in d.items(): print('key: &#123;&#125;, value: &#123;&#125;'.format(k, v)) while循环while循环，表示当condition满足时，一直重复循环执行某段程序，直到condition不再满足，就跳出循环体。12while condition: 执行语句..... 很多时候，for循环和while循环可以相互转换，比如要遍历一个列表，用while循环同样可以完成。12345list = [1, 2, 3, 4, 5]index = 0while index &lt; len(list): print(list[index]) index += 1 也可以在 while 循环中添加判断逻辑123456count = 0while count &lt; 3: print('count 小于3') count += 1else: print('count 大于等于3') break用法break可以跳出for循环和while循环。如果从for或while循环跳出，相应的循环else代码块将不执行。示例：123456789101112for char in 'hello world': if char == 'l': break print(char)count = 0while count &lt; 10: if count &gt;= 5: break print(count) count += 1 continue用法continue语句用来跳过当前循环块中的剩余语句，然后进行下一轮循环。123456i = 1while i &lt; 10: i += 1 if i%2 &gt; 0: # 非双数时跳过输出 continue print(i) 条件与循环的复用前面我们介绍了条件与循环的基本操作，接下来我们来看看它们的进阶操作，让程序变得更简洁高效。 在阅读别人代码时，我们会发现，很多将条件和循环并做一行的写法，如：1expression1 if condition else expression2 for item in iterable 我们将上面的表达式分解成多行代码，等同于下方的嵌套结构：12345for item in iterable: if condition1: expression1 else: expression2 如果表达式中没有else语句，则需要写成：1expression1 for item in iterable if condition1 接下来我们用两个例子来熟悉一下这种写法。 1、我们要绘制y = 2*|x| + 5 的函数图像，给定集合x的数据点，需要计算出y的数据集合123x = [-2, -1, 0, 1, 2]y = [value * 2 + 5 if value &gt; 0 else -value * 2 + 5 for value in x]print(y) 2、将文件中逐行读取的一个完整语句，按逗号分割单词，去掉首位的空字符，并过滤掉长度小于等于5的单词，最后返回由单词组成的列表123text = ' Today , is, Sunday 'text_list = [s.strip() for s in text.split(',') if len(s) &gt; 5]print(text_list) 当然，这样的复用并不仅仅局限于一个循环。比如：给定两个列表x、y, 要求返回x、y中所有元素对组成的元组，相等的情况除外。那么，我们可以用下面的表达式表示出来：1[(xx, yy) for xx in x for yy in y if xx != yy] 写法等价于：12345l = []for xx in x: for yy in y: if xx != yy: l.append((xx, yy)) 熟练之后，你会发现这种写法非常方便。当然，如果遇到逻辑很复杂的复用，你可能会觉得写成一行难以理解、容易出错。那种情况下，用正常的形式表达，也不失为一种好的规范和选择。 下面的一个练习题，大家尝试分别用一行和多行条件循环语句来实现，参考代码点击文末示例代码链接获取。1234567891011给定下面两个列表attributes和values，要求针对values中每一组子列表value，输出其和attributes中的键对应后的字典，最后返回字典组成的列表。attributes = ['name', 'dob', 'gender']values = [['jason', '2000-01-01', 'male'], ['mike', '1999-01-01', 'male'],['nancy', '2001-02-01', 'female']]# expected output:[&#123;'name': 'jason', 'dob': '2000-01-01', 'gender': 'male'&#125;, &#123;'name': 'mike', 'dob': '1999-01-01', 'gender': 'male'&#125;, &#123;'name': 'nancy', 'dob': '2001-02-01', 'gender': 'female'&#125;] 总结 在条件语句中，if可以单独使用，但是elif和else必须和if同时搭配使用；而If条件语句的判断，除了boolean类型外，其他的最好显示出来。 在for循环中，如果需要同时访问索引和元素，你可以使用enumerate()函数来简化代码。 写条件与循环时，合理利用continue或者break来避免复杂的嵌套，是十分重要的。 要注意条件与循环的复用，简单功能往往可以用一行直接完成，极大地提高代码质量与效率。 文中示例代码： python-learning 未完待续，持续更新中……","categories":[{"name":"Python","slug":"Python","permalink":"http://www.chenhanpeng.com/categories/Python/"}],"tags":[{"name":"python教程","slug":"python教程","permalink":"http://www.chenhanpeng.com/tags/python教程/"},{"name":"条件与循环","slug":"条件与循环","permalink":"http://www.chenhanpeng.com/tags/条件与循环/"}]},{"title":"Python从小白到攻城狮(5)——深入浅出字符串","slug":"python_series/python_5_深入浅出字符串","date":"2019-08-25T14:54:02.000Z","updated":"2019-09-18T12:20:31.910Z","comments":true,"path":"2019/08/25/python_series/python_5_深入浅出字符串/","link":"","permalink":"http://www.chenhanpeng.com/2019/08/25/python_series/python_5_深入浅出字符串/","excerpt":"","text":"在《Python从小白到攻城狮（2）：数据类型和变量》中，我们简单介绍过字符串，今天这篇文章，我们将一起学习字符串的更多知识。 字符串基础 字符串(string)是Python中很常见的一种数据类型，在日志的打印、函数的注释、数据库的访问、变量的基本操作等等中都用到了字符串。 字符串是以单引号(&#39;) 、双引号(&quot;) 或者三引号(&#39;&#39;&#39; 或 &quot;&quot;&quot;)括起来的任意文本。 在python中单引号、双引号、三引号的字符串是一模一样的，没有区别。 我们来看一下字符串的几种写法：1234567name = 'zhang san'city = \"Fujian\"s1 = 'hello world's2 = \"hello world\"s3 = \"\"\"hello world\"\"\"print(s1 == s2 == s3) # 返回True说明s1 s2 s3完全一样 Python的字符串同时支持三种表达方式，主要是方便我们在字符串中，内嵌带引号的字符串。比如：12\"I'm a coder\"\"hello 'world'\" 三引号字符串，主要应用于多行字符串的情境，比如函数的注释等等。123456789def function_notes(value1, value2): \"\"\" args: value1: number value2: number return value1 + value2 \"\"\" return value1 + value2 Python也支持转义字符。 转义字符：用反斜杠开头的字符串，来表示一些特定意义的字符。常见的转义字符见下表： 1234567&gt;&gt;&gt; s = 'a\\nb\\tc\\''&gt;&gt;&gt; print(s)ab c'&gt;&gt;&gt; print(len(s))6 虽然字符串s打印的输出横跨了两行，但是整个字符串s仍然只有6个元素。 在转义字符中，最常见的是换行符\\n的使用。在文件读取时，如果我们一行一行读取，那么每行字符串的末尾，都会包含换行符\\n。在最后进行数据处理时，我们往往会去掉每一行的末尾的换行符。 字符串的常用操作 Python的字符串支持索引、切片和遍历等操作。 和其他数据结构一样，字符串的索引也是从0开始，index=0表示第一个元素（字符），[index:index+2]表示第index个元素到index+1个元素组成的子字符串。123text = 'welcom to china'print(text[0])print(text[1:4]) 遍历字符串同样很简单，相当于遍历字符串中的每个字符123text = 'welcom to china'for char in text: print(char) 特别要注意，Python的字符串是不可变的（immutable）。Python中字符串的改变，通常只能通过创建新的字符串来完成。比如：我们想把&#39;hello&#39;的第一个字符&#39;h&#39;，改为大写的&#39;H&#39;，可以采用下面的做法：12s = 'H' + s[1:]s = s.replace('h', 'H') 第一种方法，是直接用大写的&#39;H&#39;，通过加号&#39;+&#39;操作符，与原字符串切片操作的子字符串拼接而成新的字符串。 第二种方法，是直接扫描原字符串，把小写的&#39;h&#39;替换成大写的&#39;H&#39;，得到新的字符串。 字符串常用的函数还有下面几个： string.strip(str)：表示去掉首尾的str字符串 string.lstrip(str)：表示只去掉开头的str字符串 string.rstrip(str)：表示只去掉尾部的str字符串 string.find(sub, start, end)：表示从start到end查找字符串中子字符串sub的位置等等 string.split(separator)：表示把字符串按照separator分割成子字符串，并返回一个分割后子字符串组合的列表 下面我们通过一些练习来熟悉字符串的操作：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051str1 = \"hello World!\"# 利用len函数计算字符串长度print(len(str1)) # 12# 获取字符串首字母大写的拷贝print(str1.capitalize()) # Hello world!# 获取字符串变大写后的拷贝print(str1.upper()) # HELLO WORLD!# find函数查找子串的位置print(str1.find('llo')) # 2print(str1.find('hot')) # -1# # index查找子串，但找不到子串或报错# print(str1.index('llo'))# print(str1.index('hot'))# 判断字符串是否以指定的字符串开头print(str1.startswith('he')) # Trueprint(str1.startswith('ha')) # False# 判断字符串是否以指定的字符串结尾print(str1.endswith('d!')) # Trueprint(str1.endswith('ld')) # False# 将字符串以指定的宽度居中并在两侧填充指定的字符print(str1.center(50, '='))# 将字符串以指定的宽度靠右放置左侧填充指定的字符print(str1.rjust(50, '-'))str2 = '1234abcd'# 索引操作print(str2[3]) # 4# 字符串切片操作(从指定的位置开始索引)print(str2[2:5]) # 34aprint(str2[2:]) # 34abcdprint(str2[2::2]) # 3acprint(str2[::2]) # 13acprint(str2[::-1]) # dcba4321print(str2[-3:-1]) # bc# 检查字符串是否由数字构成print(str2.isdigit()) # False# 检查字符串是否以字母构成print(str2.isalpha()) # False# 检查字符串是否以数字和字母构成print(str2.isalnum()) # Truestr3 = ' my name is zhangsan '# 获得字符串修剪头尾空格后的拷贝print(str3.strip()) # my name is zhangsan 字符串的格式化 什么是字符串的格式化？通常，我们使用一个字符串作为模板，模板中会有格式符。这些格式符为后续真实值预留位置，以呈现出真实值应该呈现的样式。字符串的格式化，通常会用在程序的输出、logging等场景。 比如：我们有一个任务，给定一个用户的userid，要去数据库中查询该用户的一些信息，并返回。如果数据库中没有此人的信息，我们通常会记录下来，这样有利于往后的日志分析，或者是线上bug的调试等。123id = 123456nanme = 'zhangsan'print('no data available for person with id: &#123;&#125;, name: &#123;&#125;'.format(id, name)) 其中string.format()就是格式化函数，大括号{}就是所谓的格式符，用来为后面的真实值————变量id、name预留位置。 不过要注意，string.format()是最新的字符串格式函数与规范。自然，我们还有其他的表示方法，比如在Python之前版本中，字符串格式化通常用%来表示，那么上述的例子，就可以写成下面这样：1print('no data available for person with id: %s, name: %s' % (id, name)) 其中%s表示字符串型，%d表示整型等等，这些属于常识，你应该都了解。 当然，现在你写程序时，我还是推荐使用format函数，毕竟这是最新规范，也是官方文档推荐的规范。 也许有人会问，为什么非要使用格式化函数，上述例子用字符串的拼接不也能完成吗？没错，在很多情况下，字符串拼接确实能满足格式化函数的需求。但是使用格式化函数，更加清晰、易读，并且更加规范，不易出错。 文中示例代码： python-learning 未完待续，持续更新中……","categories":[{"name":"Python","slug":"Python","permalink":"http://www.chenhanpeng.com/categories/Python/"}],"tags":[{"name":"python教程","slug":"python教程","permalink":"http://www.chenhanpeng.com/tags/python教程/"},{"name":"字符串","slug":"字符串","permalink":"http://www.chenhanpeng.com/tags/字符串/"}]},{"title":"Python从小白到攻城狮(4)——字典和集合","slug":"python_series/python_4_字典和集合","date":"2019-08-21T12:09:49.000Z","updated":"2019-09-18T12:20:50.210Z","comments":true,"path":"2019/08/21/python_series/python_4_字典和集合/","link":"","permalink":"http://www.chenhanpeng.com/2019/08/21/python_series/python_4_字典和集合/","excerpt":"","text":"在前面的一篇文章 《Python从小白到攻城狮（3）：列表和元组》中，我们学习了列表和元组，了解了其基本操作和性能比较。今天这篇文章，我们来学习两个同样很常见并且很有用的数据结构：字典（dict）和集合（set）。字典和集合在 Python 被广泛使用，并且性能进行了高度优化，其重要性不言而喻。 字典(dict) 什么是字典字典，dict全称dictionary，在其他语言中也称为map，是一系列无序元素的组合，其长度大小可变，元素可以任意地删减和改变。 字典的元素是一对键(key)和值(value)的配对，和列表/元组相比，字典的性能更优，尤其是对于查找、添加和删除操作，字典都能在常数时间复杂度内完成。 字典的创建字典的创建，通常有下面几种方式：1234567d1 = &#123;'name': 'jack', 'age': 20, 'gender': 'male'&#125;d2 = dict(&#123;'name': 'jack', 'age': 20, 'gender': 'male'&#125;)d3 = dict([('name', 'jack'), ('age', 20), ('gender', 'male')])d4 = dict(name='jack', age=20, gender='male')d1 == d2 == d3 == d4True # 返回True，说明创建的4个字典是一样的 元素访问刚才我们学习了如何创建字典，我们再来看元素访问的问题。字典访问可以直接索引键，如果不存在，就会抛出异常： 1234567d = &#123;'name': 'jack', 'age': 20, 'gender': 'male'&#125;d['name']'jack'd['location']Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;KeyError: 'location' 要避免出现key不存在的错误，我们可以通过in来判断key是否存在123456d = &#123;'name': 'jack', 'age': 20&#125;'name' in dTrue'location' in dFalse 也可以使用dict提供的get(key, default)函数来进行索引。如果键不存在，调用get()函数可以返回None, 或者返回自己指定的一个默认值。比如下面这个示例，返回了 12345d = &#123;'name': 'jack', 'age': 20, 'gender': 'male'&#125;d.get('name')'jack'd.get('location', 'null')'null' 注意：返回None的时候Python的交互环境不显示结果。 增、删、更新操作字典支持增加、删除、更新等操作。 123456789101112131415# 增加d = &#123;'name': 'jason', 'age': 20&#125;d['gender'] = 'male' # 增加元素对'gender': 'male'd['dob'] = '1999-02-01' # 增加元素对'dob': '1999-02-01'd&#123;'name': 'jason', 'age': 20, 'gender': 'male', 'dob': '1999-02-01'&#125;# 更新d['dob'] = '1998-01-01' # 更新键'dob'对应的值 # 删除d.pop('dob') # 删除键为'dob'的元素对'1998-01-01'd&#123;'name': 'jason', 'age': 20, 'gender': 'male'&#125; 排序对于字典，我们通常会根据键或值，进行升序或降序排序： 1234567d = &#123;'b': 1, 'a': 2, 'c': 10&#125;d_sorted_by_key = sorted(d.items(), key=lambda x: x[0]) # 根据字典键的升序排序d_sorted_by_value = sorted(d.items(), key=lambda x: x[1]) # 根据字典值的升序排序d_sorted_by_key[('a', 2), ('b', 1), ('c', 10)]d_sorted_by_value[('b', 1), ('a', 2), ('c', 10)] 当然，因为字典本身是无序的，所以这里返回了一个列表。列表中的每个元素，是由原字典的键和值组成的元组。 集合(set) 什么是集合集合和字典类似，也是一组key的集合，但是不存储value。由于key不能重复，所以集合是一系列无序的、唯一的元素组合。 集合的创建1234s1 = &#123;1, 2, 3&#125;s2 = set([1, 2, 3])s1 == s2True 操作集合并不支持索引操作，因为集合本质上是一个哈希表，和列表不一样。所以，下面这样的操作是错误的，Python 会抛出异常： 12345s = &#123;1, 2, 3&#125;s[0]Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;TypeError: 'set' object does not support indexing 和字典一样，我们可以通过in来判断一个元素是否在集合中。 12345s = &#123;1, 2, 3&#125;1 in sTrue10 in sFalse 集合也同样支持增加、删除、更新等操作。s.add(x)：将元素 x 添加到集合 s 中，如果元素已存在，则不进行任何操作。 update()： 方法用于修改当前集合，可以添加新的元素或集合到当前集合中，如果添加的元素在集合中已存在，则该元素只会出现一次，重复的会忽略。 s.remove( x )：将元素 x 从集合 s 中移除，如果元素不存在，则会发生错误。 s.discard(x)：移除集合中的元素，且如果元素不存在，不会发生错误。 123456789101112131415161718192021s = &#123;1, 2, 3&#125;s.add(4) # 增加元素 4 到集合s&#123;1, 2, 3, 4&#125;# update()方法s = &#123;1, 2, 3&#125;s1 = &#123;3, 4, 5&#125;s.update(s1)print(s)&#123;1, 2, 3, 4, 5&#125;s.remove(4) # 从集合中删除元素 4s&#123;1, 2, 3&#125;s.remove(6)Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;KeyError: 6s.discard(6) 不过要注意，集合的 pop() 操作是删除集合中最后一个元素，可是集合本身是无序的，你无法知道会删除哪个元素，因此这个操作得谨慎使用。 排序而对于集合，其排序和前面讲过的列表、元组很类似，直接调用 sorted(set) 即可，结果会返回一个排好序的列表。 123s = &#123;3, 4, 2, 1&#125;sorted(s) # 对集合的元素进行升序排序[1, 2, 3, 4] 字典和集合性能 字典和集合是进行过性能高度优化的数据结构，特别是对于查找、添加和删除操作。那接下来，就来看看，它们在具体场景下的性能表现，以及与列表等其他数据结构的对比。 比如电商企业的后台，存储了每件产品的ID、名称和价格。现在的需求是，给定某件商品的ID，我们要找出其价格。 如果我们用列表来存储这些数据结构，并进行查找，相应的代码如下： 12345678910111213141516def find_product_price(products, product_id): for id, price in products: if id == product_id: return price return None products = [ (143121312, 100), (432314553, 30), (32421912367, 150) ] print('The price of product 432314553 is &#123;&#125;'.format(find_product_price(products, 432314553))) # 输出The price of product 432314553 is 30 假设列表有 n 个元素，而查找的过程要遍历列表，那么时间复杂度就为 O(n)。即使我们先对列表进行排序，然后使用二分查找，也会需要 O(logn) 的时间复杂度，更何况，列表的排序还需要 O(nlogn) 的时间。 但如果我们用字典来存储这些数据，那么查找就会非常便捷高效，只需 O(1) 的时间复杂度就可以完成。原因也很简单，刚刚提到过的，字典的内部组成是一张哈希表，你可以直接通过键的哈希值，找到其对应的值。 123456789products = &#123; 143121312: 100, 432314553: 30, 32421912367: 150&#125;print('The price of product 432314553 is &#123;&#125;'.format(products[432314553])) # 输出The price of product 432314553 is 30 类似的，现在需求变成，要找出这些商品有多少种不同的价格。我们还用同样的方法来比较一下。 如果还是选择使用列表，对应的代码如下，其中，A 和 B 是两层循环。同样假设原始列表有 n 个元素，那么，在最差情况下，需要 O(n^2) 的时间复杂度。 123456789101112131415161718# list versiondef find_unique_price_using_list(products): unique_price_list = [] for _, price in products: # A if price not in unique_price_list: #B unique_price_list.append(price) return len(unique_price_list) products = [ (143121312, 100), (432314553, 30), (32421912367, 150), (937153201, 30)]print('number of unique price is: &#123;&#125;'.format(find_unique_price_using_list(products))) # 输出number of unique price is: 3 但如果我们选择使用集合这个数据结构，由于集合是高度优化的哈希表，里面元素不能重复，并且其添加和查找操作只需 O(1) 的复杂度，那么，总的时间复杂度就只有 O(n)。 1234567891011121314151617# set versiondef find_unique_price_using_set(products): unique_price_set = set() for _, price in products: unique_price_set.add(price) return len(unique_price_set) products = [ (143121312, 100), (432314553, 30), (32421912367, 150), (937153201, 30)]print('number of unique price is: &#123;&#125;'.format(find_unique_price_using_set(products))) # 输出number of unique price is: 3 可能你对这些时间复杂度没有直观的认识，我可以举一个实际工作场景中的例子，让你来感受一下。 下面的代码，初始化了含有 100,000 个元素的产品，并分别计算了使用列表和集合来统计产品价格数量的运行时间： 1234567891011121314151617181920import timeid = [x for x in range(0, 100000)]price = [x for x in range(200000, 300000)]products = list(zip(id, price)) # 计算列表版本的时间start_using_list = time.perf_counter()find_unique_price_using_list(products)end_using_list = time.perf_counter()print(\"time elapse using list: &#123;&#125;\".format(end_using_list - start_using_list))## 输出time elapse using list: 70.1450754 # 计算集合版本的时间start_using_set = time.perf_counter()find_unique_price_using_set(products)end_using_set = time.perf_counter()print(\"time elapse using set: &#123;&#125;\".format(end_using_set - start_using_set))# 输出time elapse using set: 0.019779799999994907 你可以看到，仅仅十万的数据量，两者的速度差异就如此之大。事实上，大型企业的后台数据往往有上亿乃至十亿数量级，如果使用了不合适的数据结构，就很容易造成服务器的崩溃，不但影响用户体验，并且会给公司带来巨大的财产损失。 字典和集合的工作原理 我们通过举例以及与列表的对比，看到了字典和集合操作的高效性。不过，字典和集合为什么能够如此高效，特别是查找、插入和删除操作？ 这当然和字典、集合内部的数据结构密不可分。不同于其他数据结构，字典和集合的内部结构都是一张哈希表。 对于字典而言，这张表存储了哈希值（hash）、键和值这 3 个元素。 而对集合来说，区别就是哈希表内没有键和值的配对，只有单一的元素了。 我们来看，老版本 Python 的哈希表结构如下所示： 1234567891011--+-------------------------------+ | 哈希值 (hash) 键 (key) 值 (value)--+-------------------------------+0 | hash0 key0 value0--+-------------------------------+1 | hash1 key1 value1--+-------------------------------+2 | hash2 key2 value2--+-------------------------------+. | ...__+_______________________________+ 不难想象，随着哈希表的扩张，它会变得越来越稀疏。举个例子，比如我有这样一个字典： 1&#123;'name': 'mike', 'dob': '1999-01-01', 'gender': 'male'&#125; 那么它会存储为类似下面的形式： 123456789entries = [['--', '--', '--'][-230273521, 'dob', '1999-01-01'],['--', '--', '--'],['--', '--', '--'],[1231236123, 'name', 'mike'],['--', '--', '--'],[9371539127, 'gender', 'male']] 这样的设计结构显然非常浪费存储空间。为了提高存储空间的利用率，现在的哈希表除了字典本身的结构，会把索引和哈希值、键、值单独分开，也就是下面这样新的结构： 123456789101112131415Indices----------------------------------------------------None | index | None | None | index | None | index ...---------------------------------------------------- Entries--------------------hash0 key0 value0---------------------hash1 key1 value1---------------------hash2 key2 value2--------------------- ...--------------------- 那么，刚刚的这个例子，在新的哈希表结构下的存储形式，就会变成下面这样： 123456indices = [None, 1, None, None, 0, None, 2]entries = [[1231236123, 'name', 'mike'],[-230273521, 'dob', '1999-01-01'],[9371539127, 'gender', 'male']] 我们可以很清晰地看到，空间利用率得到很大的提高。 清楚了具体的设计结构，我们接着来看这几个操作的工作原理。 插入操作每次向字典或集合插入一个元素时，Python 会首先计算键的哈希值（hash(key)），再和 mask = PyDicMinSize - 1 做与操作，计算这个元素应该插入哈希表的位置 index = hash(key) &amp; mask。如果哈希表中此位置是空的，那么这个元素就会被插入其中。 而如果此位置已被占用，Python 便会比较两个元素的哈希值和键是否相等。 若两者都相等，则表明这个元素已经存在，如果值不同，则更新值。 若两者中有一个不相等，这种情况我们通常称为哈希冲突（hash collision），意思是两个元素的键不相等，但是哈希值相等。这种情况下，Python 便会继续寻找表中空余的位置，直到找到位置为止。 值得一提的是，通常来说，遇到这种情况，最简单的方式是线性寻找，即从这个位置开始，挨个往后寻找空位。当然，Python 内部对此进行了优化（这一点无需深入了解，你有兴趣可以查看源码，我就不再赘述），让这个步骤更加高效。 查找操作和前面的插入操作类似，Python 会根据哈希值，找到其应该处于的位置；然后，比较哈希表这个位置中元素的哈希值和键，与需要查找的元素是否相等。如果相等，则直接返回；如果不等，则继续查找，直到找到空位或者抛出异常为止。 删除操作对于删除操作，Python 会暂时对这个位置的元素，赋于一个特殊的值，等到重新调整哈希表的大小时，再将其删除。 不难理解，哈希冲突的发生，往往会降低字典和集合操作的速度。因此，为了保证其高效性，字典和集合内的哈希表，通常会保证其至少留有 1/3 的剩余空间。随着元素的不停插入，当剩余空间小于 1/3 时，Python 会重新获取更大的内存空间，扩充哈希表。不过，这种情况下，表内所有的元素位置都会被重新排放。 虽然哈希冲突和哈希表大小的调整，都会导致速度减缓，但是这种情况发生的次数极少。所以，平均情况下，这仍能保证插入、查找和删除的时间复杂度为 O(1)。 总结 字典和集合都是无序的数据结构，其内部的哈希表存储结构，保证了其查找、插入、删除操作的高效性。 所以，字典和集合通常运用在对元素的高效查找、去重等场景。 文中示例代码： python-learning 未完待续，持续更新中……","categories":[{"name":"Python","slug":"Python","permalink":"http://www.chenhanpeng.com/categories/Python/"}],"tags":[{"name":"python教程","slug":"python教程","permalink":"http://www.chenhanpeng.com/tags/python教程/"},{"name":"字典/集合","slug":"字典-集合","permalink":"http://www.chenhanpeng.com/tags/字典-集合/"}]},{"title":"Python从小白到攻城狮(3)——列表和元组","slug":"python_series/python_3_列表和元组","date":"2019-08-08T01:01:57.000Z","updated":"2019-09-18T12:21:15.171Z","comments":true,"path":"2019/08/08/python_series/python_3_列表和元组/","link":"","permalink":"http://www.chenhanpeng.com/2019/08/08/python_series/python_3_列表和元组/","excerpt":"","text":"Python内置了多种类型的数据结构，常用的有：列表、元组、集合和字典。 本文主要介绍列表和元组。 列表(list)和元组(tuple)定义列表和元组，都是一个可以放置任意数据类型的有序集合。 列表和元组的区别 列表是动态的，长度大小不固定，可以随意增加、删减或者改变元素（mutable）。 元组是静态的，长度大小固定，无法增加删减或改变（immutable）。 如果要对已有的元组做任何“改变”，只能重新开辟一块内存，创建新的元组。 123456789# 列表(list)list = [1, 2, 3, 4, 5]list.append(6) # 添加元素 5 到原列表的末尾print(list)# 元组tup = (1, 2, 3, 4)new_tup = tup + (5, ) # 创建新的元组 new_tup，并依次填充原元组的值print(new_tup) 列表和元组的基本操作和注意事项索引在python中，列表和元组都支持负数索引，-1表示最后一个元素，-2表示倒数第2个元素，以此类推 123456789# 列表list = [1, 2, 3, 4]list[0]list[-1]# 元组tup = (1, 2, 3, 4)tup[1]tup[-2] 切片操作列表和元组都支持切片操作1234567list = [1, 2, 3, 4]l[1:3] # 返回列表中索引从 1 到 2 的子列表[2, 3] tup = (1, 2, 3, 4)tup[1:3] # 返回元组中索引从 1 到 2 的子元组(2, 3) 随意嵌套123l = [[1, 2, 3], [4, 5]] # 列表的每一个元素也是一个列表 tup = ((1, 2, 3), (4, 5, 6)) # 元组的每一个元素也是一元组 列表和元组的相互转换两者可以通过 list() 和 tuple() 函数相互转换： 12345list((1, 2, 3))[1, 2, 3] tuple([1, 2, 3])(1, 2, 3) 常用的内置函数 count(item) 表示统计列表 / 元组中 item 出现的次数。 index(item) 表示返回列表 / 元组中 item 第一次出现的索引。 list.reverse() 和 list.sort() 分别表示原地倒转列表和排序（注意，元组没有内置的这两个函数)。 reversed() 和 sorted() 同样表示对列表 / 元组进行倒转和排序，但是会返回一个倒转后或者排好序的新的列表 / 元组。 123456789101112131415161718192021l = [3, 2, 3, 7, 8, 1]l.count(3) 2l.index(7)3l.reverse()l[1, 8, 7, 3, 2, 3]l.sort()l[1, 2, 3, 3, 7, 8] tup = (3, 2, 3, 7, 8, 1)tup.count(3)2tup.index(7)3list(reversed(tup))[1, 8, 7, 3, 2, 3]sorted(tup)[1, 2, 3, 3, 7, 8] 列表和元组存储方式的差异前面我们说过：列表和元组最重要的区别就是，列表是动态的、可变的，而元组是静态的、不可变的。这样的差异，势必会影响两者存储方式。我们先看下面的例子： 123456l = [1, 2, 3]l.__sizeof__()64tup = (1, 2, 3)tup.__sizeof__()48 上面的例子中，我们在列表和元组中放置了相同的元素，但是元组的存储空间，却比列表要少 16 字节。这是为什么呢？ 事实上，由于列表是动态的，所以它需要存储指针，来指向对应的元素（上述例子中，对于 int 型，8 字节）。另外，由于列表可变，所以需要额外存储已经分配的长度大小（8 字节），这样才可以实时追踪列表空间的使用情况，当空间不足时，及时分配额外空间。 123456789101112131415161718l = []l.__sizeof__() // 空列表的存储空间为 40 字节40l.append(1)l.__sizeof__() 72 // 加入了元素 1 之后，列表为其分配了可以存储 4 个元素的空间 (72 - 40)/8 = 4l.append(2) l.__sizeof__()72 // 由于之前分配了空间，所以加入元素 2，列表空间不变l.append(3)l.__sizeof__() 72 // 同上l.append(4)l.__sizeof__() 72 // 同上l.append(5)l.__sizeof__() 104 // 加入元素 5 之后，列表的空间不足，所以又额外分配了可以存储 4 个元素的空间 上面的例子，大概描述了列表空间分配的过程。我们可以看到，为了减小每次增加 / 删减操作时空间分配的开销，Python 每次分配空间时都会额外多分配一些，这样的机制（over-allocating）保证了其操作的高效性：增加 / 删除的时间复杂度均为 O(1)。 但是对于元组，情况就不同了。元组长度大小固定，元素不可变，所以存储空间固定。 在数据量小的情况下，这样的差异可以忽略不计。但是当数据量很大时，比如列表和元组存储元素的个数是一亿，十亿甚至更大数量级时，这种差异就不能忽视了。 列表和元组的性能通过上面列表和元组存储方式的差异的学习，我们可以得出结论：元组要比列表更加轻量级一些，所以总体上来说，元组的性能速度要略优于列表。 另外，Python 会在后台，对静态数据做一些资源缓存（resource caching）。通常来说，因为垃圾回收机制的存在，如果一些变量不被使用了，Python 就会回收它们所占用的内存，返还给操作系统，以便其他变量或其他应用使用。 但是对于一些静态变量，比如元组，如果它不被使用并且占用空间不大时，Python 会暂时缓存这部分内存。这样，下次我们再创建同样大小的元组时，Python 就可以不用再向操作系统发出请求，去寻找内存，而是可以直接分配之前缓存的内存空间，这样就能大大加快程序的运行速度。 下面的例子，是计算初始化一个相同元素的列表和元组分别所需的时间。我们可以看到，元组的初始化速度，要比列表快 5 倍。 1234python -m timeit 'x=(1,2,3,4,5,6)'20000000 loops, best of 5: 9.97 nsec per looppython -m timeit 'x=[1,2,3,4,5,6]'5000000 loops, best of 5: 50.1 nsec per loop 但如果是索引操作的话，两者的速度差别非常小，几乎可以忽略不计。 1234python -m timeit -s 'x=[1,2,3,4,5,6]' 'y=x[3]'10000000 loops, best of 5: 22.2 nsec per looppython -m timeit -s 'x=(1,2,3,4,5,6)' 'y=x[3]'10000000 loops, best of 5: 21.9 nsec per loop 当然，如果你想要增加、删减或者改变元素，那么列表显然更优。原因你现在肯定知道了，那就是对于元组，你必须得通过新建一个元组来完成。 列表和元组的使用场景那么列表和元组到底用哪一个呢？根据上面所说的特性，我们具体情况具体分析。 1. 如果存储的数据和数量不变，比如你有一个函数，需要返回的是一个地点的经纬度，然后直接传给前端渲染，那么肯定选用元组更合适。 123def get_location(): ..... return (longitude, latitude) 2. 如果存储的数据或数量是可变的，比如社交平台上的一个日志功能，是统计一个用户在一周之内看了哪些用户的帖子，那么则用列表更合适。 1234viewer_owner_id_list = [] # 里面的每个元素记录了这个 viewer 一周内看过的所有 owner 的 idrecords = queryDB(viewer_id) # 索引数据库，拿到某个 viewer 一周内的日志for record in records: viewer_owner_id_list.append(record.id) 总结 列表和元组都是有序的，可以存储任意数据类型的集合。 列表是动态的，长度可变，可以随意增加、删减、改变元素。 元组是静态的，长度大小固定，不可对元素进行增加、删减、改变操作。 列表的存储空间略大于元组，性能略逊于元组。元组相对列表更轻量级。","categories":[{"name":"Python","slug":"Python","permalink":"http://www.chenhanpeng.com/categories/Python/"}],"tags":[{"name":"python教程","slug":"python教程","permalink":"http://www.chenhanpeng.com/tags/python教程/"},{"name":"列表","slug":"列表","permalink":"http://www.chenhanpeng.com/tags/列表/"},{"name":"元组","slug":"元组","permalink":"http://www.chenhanpeng.com/tags/元组/"}]},{"title":"Python从小白到攻城狮(2)——数据类型和变量","slug":"python_series/python_2_数据类型和变量","date":"2019-08-06T13:31:03.000Z","updated":"2019-09-18T12:22:20.675Z","comments":true,"path":"2019/08/06/python_series/python_2_数据类型和变量/","link":"","permalink":"http://www.chenhanpeng.com/2019/08/06/python_series/python_2_数据类型和变量/","excerpt":"","text":"本系列Python文章基于Python3版本，关于python的安装和配置自行百度，这里不做详细介绍。 接下来将介绍Python基础——数据类型和变量。 数据类型在Python中，能够直接处理的数据类型有以下几种： 整型Python中可以处理任意大的整数，包括负整数。支持二进制（如0b100，换算成十进制是4）、八进制（0o100，换算成十进制是64）、十六进制（0x100，换算成十进制为256）的表示法。 浮点型浮点数也就是小数，之所以称为浮点数，是因为按照科学记数法表示时，一个浮点数的小数点位置是可变的，比如，1.23x10^9和12.3x10^8是完全相等的。浮点数除了数学写法（如123.456）之外还支持科学计数法（如1.23456e2）。 字符串型字符串是以单引号 &#39;或双引号&quot;括起来的任意文本，比如’Hello’或”Hello”。字符串还有原始字符串表示法、字节字符串表示法、Unicode字符串表示法，而且可以书写成多行的形式（用三个单引号或三个双引号开头，三个单引号或三个双引号结尾）。 如果字符串内部既包括 &#39; 又包括 &quot; ，可以用转义字符 \\ 来标识。 转义字符可以转义很多字符，比如 \\n 表示换行， \\t表示制表符，字符\\ 本身也要转义，所以\\\\表示字符就是\\。 123a = 'I\\'m \\\"OK\\\"!' # 表示： I'm \"OK\"!print(a)print('\\\\\\n\\\\\\t\\\\') 布尔型布尔值只有True、False两种值，要么是True，要么是False，在Python中，可以直接用True、False表示布尔值（请注意大小写），也可以通过布尔运算计算出来（例如3 &lt; 5会产生布尔值True，而2 == 1会产生布尔值False）。 12345678&gt;&gt;&gt; TrueTrue&gt;&gt;&gt; FalseFalse&gt;&gt;&gt; 3 &gt; 2True&gt;&gt;&gt; 3 &gt; 5False 复数型形如3+5j，跟数学上的复数表示一样，唯一不同的是虚部的i换成了j。 空值空值是Python一个特殊的值，用None表示。None不能理解为0，因为0是有意义的，而None是一个特殊的空值。 变量变量的概念基本上和初中代数的方程变量是一致的，只是在计算机程序中，变量不仅可以是数字，还可以是任意数据类型。 变量命名变量在程序中就是用一个变量名表示了，变量名必须是大小写英文、数字和_的组合，且不能用数字开头。 变量的使用123456789101112131415161718192021222324252627282930a = 123b = 14print(a + b)print(a - b)\"\"\"使用input()函数获取键盘输入使用int()进行类型转换用占位符格式化输出的字符串\"\"\"a = int(input('a = '))b = int(input('b = '))print('%d * %d = %d' % (a, b, a * b))print('%d / %d = %f' % (a, b, a / b))print('%d // %d = %d' % (a, b, a // b))\"\"\"使用type()检查变量的类型\"\"\"a = 100b = 12.345c = 1 + 5jd = 'hello, world'e = Trueprint(type(a))print(type(b))print(type(c))print(type(d))print(type(e)) 在对变量类型进行转换时可以使用Python的内置函数（准确的说下面列出的并不是真正意义上的函数，而是后面我们要讲到的创建对象的构造方法）。 int()：将一个数值或字符串转换成整数，可以指定进制。 float()：将一个字符串转换成浮点数。 str()：将指定的对象转换成字符串形式，可以指定编码。 chr()：将整数转换成该编码对应的字符串（一个字符）。 ord()：将字符串（一个字符）转换成对应的编码（整数）。 运算符Python支持多种运算符，下表大致按照优先级从高到低的顺序列出了所有的运算符，我们会陆续使用到它们。 运算符 描述 [] [:] 下标，切片 ** 指数 ~ + - 按位取反, 正负号 * / % // 乘，除，模，整除 + - 加，减 &gt;&gt; &lt;&lt; 右移，左移 &amp; 按位与 ^ &#124; 按位异或，按位或 &lt;= &lt; &gt; &gt;= 小于等于，小于，大于，大于等于 == != 等于，不等于 is is not 身份运算符 in not in 成员运算符 not or and 逻辑运算符 = += -= *= /= %= //= **= &amp;= &#124;= ^= &gt;&gt;= &lt;&lt;= （复合）赋值运算符 说明： 在实际开发中，如果搞不清楚运算符的优先级，可以使用括号来确保运算的执行顺序。 运算符的使用123456789101112131415161718192021222324252627\"\"\"运算符的使用\"\"\"a = 5b = 10c = 3d = 4e = 5a += ba -= ca *= da /= eprint(\"a = \", a)flag1 = 3 &gt; 2flag2 = 2 &lt; 1flag3 = flag1 and flag2flag4 = flag1 or flag2flag5 = not flag1print(\"flag1 = \", flag1)print(\"flag2 = \", flag2)print(\"flag3 = \", flag3)print(\"flag4 = \", flag4)print(\"flag5 = \", flag5)print(flag1 is True)print(flag2 is not False)","categories":[{"name":"Python","slug":"Python","permalink":"http://www.chenhanpeng.com/categories/Python/"}],"tags":[{"name":"python教程","slug":"python教程","permalink":"http://www.chenhanpeng.com/tags/python教程/"}]},{"title":"Python从小白到攻城狮(1)——python环境搭建","slug":"python_series/python_1_python环境搭建","date":"2019-08-06T12:31:03.000Z","updated":"2019-09-18T12:21:28.328Z","comments":true,"path":"2019/08/06/python_series/python_1_python环境搭建/","link":"","permalink":"http://www.chenhanpeng.com/2019/08/06/python_series/python_1_python环境搭建/","excerpt":"","text":"Python介绍 Python是Guido van Rossum在1989年圣诞节期间，为了打发无聊的圣诞节而编写的一个编程语言，1991年发布第一版。 Python 是一个高层次的结合了解释性、编译性、互动性和面向对象的脚本语言。 Python 的设计具有很强的可读性，相比其他语言经常使用英文关键字，其他语言的一些标点符号，它具有比其他语言更有特色语法结构。 Python 是一种解释型语言： 这意味着开发过程中没有了编译这个环节。类似于PHP和Perl语言。 Python 是交互式语言： 这意味着，您可以在一个 Python 提示符 &gt;&gt;&gt; 后直接执行代码。 Python 是面向对象语言: 这意味着Python支持面向对象的风格或代码封装在对象的编程技术。 Python 是初学者的语言：Python 对初级程序员而言，是一种伟大的语言，它支持广泛的应用程序开发，从简单的文字处理到 WWW 浏览器再到游戏。 Python的应用领域目前Python在Web应用开发、云基础设施、DevOps、网络爬虫开发、数据分析挖掘、机器学习等领域都有着广泛的应用，因此也产生了Web后端开发、数据接口开发、自动化运维、自动化测试、科学计算和可视化、数据分析、量化交易、机器人开发、图像识别和处理等一系列的职位。 Python环境搭建 对于刚开始学习Python的新手，建议安装Anaconda。win 下安装包的时候用 anaconda 比 pip 安装要好一些，pip 有时候会因为一些依赖导致安装失败，这时候anaconda就体现出它对新手的友好。 搜索Anaconda进入官网或点击下方官网链接进入 https://www.anaconda.com/distribution/ 在页面我们可以看到windows、macOS、linux对应的安装包。 如果是初学者，建议下载Python3.X版本，而不是Python2.X。因为python的2和3版本的语法是有差异的，Python2.X将在2020年4月后不再进行任何维护。 下载安装包，双击安装。 划重点：安装过程中最好将下图所示的添加到环境变量的选项勾上。 安装之后可能程序没有自动配置anaconda环境变量，你需要手动配置！！！ 找到刚才安装的anaconda的目录，找到Scripts，打开，复制路径： 路径示例：D:\\ProgramData\\Anaconda3\\Scripts。 配置环境变量： 在Path后面添加刚才复制的路径，注意与前一个要用英文分号隔开。点击多个确定完成配置。 打开cmd 输入python，看到下面的画面，说明安装成功。 看到提示符&gt;&gt;&gt;就表示我们已经在Python交互式环境中了，可以输入任何Python代码，回车后会立即得到执行结果。输入exit()并回车，就退出Python交互模式。 第一个Python程序 Python交互模式在Python交互式环境中输入以下代码1print('Hello world!') 命令行模式通过python xxx.py运行一个.py文件 创建一个hello.py文件，文件中输入如下代码：1print('Hello World!!!') cmd的当前目录切换到hello.py所在的目录下，我的目录在 E:\\workspace\\python-learning\\1-环境搭建 ，执行下面命令可以进入到相应目录中。 1234567C:\\Users\\chenhp&gt;E:E:\\&gt;cd workspaceE:\\workspace&gt;cd python-learningE:\\workspace\\python-learning&gt;cd 1-环境搭建 在命令行中执行python hello.py，可以得到下面的执行结果： 以上内容主要介绍了windows上的环境搭建。关于macOS的环境搭建，可以百度一下安装教程，作为一个没用过mac的人就不在这里就瞎掰了。 文中示例代码： python-learning 未完待续，持续更新中……","categories":[{"name":"Python","slug":"Python","permalink":"http://www.chenhanpeng.com/categories/Python/"}],"tags":[{"name":"python教程","slug":"python教程","permalink":"http://www.chenhanpeng.com/tags/python教程/"},{"name":"python环境搭建","slug":"python环境搭建","permalink":"http://www.chenhanpeng.com/tags/python环境搭建/"}]},{"title":"带你一起用人脸识别技术判断参加美国大选的是不是吴恩达","slug":"带你一起用人脸识别技术判断参加美国大选的是不是吴恩达","date":"2019-07-31T03:19:50.000Z","updated":"2019-07-31T05:35:55.257Z","comments":true,"path":"2019/07/31/带你一起用人脸识别技术判断参加美国大选的是不是吴恩达/","link":"","permalink":"http://www.chenhanpeng.com/2019/07/31/带你一起用人脸识别技术判断参加美国大选的是不是吴恩达/","excerpt":"","text":"What！吴恩达去参加美国大选了？最近几周，想必很多人都有看到这新闻，是不是在想吴恩达老师是不是有个双胞胎兄弟去参加美国大选了？？？ 答案都不是，参选的是杨安泽，两人不仅长得像，英文名都叫Andrew，Andrew Yang（杨安泽）、Andrew Ng（吴恩达），下面是两个人的照片: 是不是分不清啊？没关系，接下来带你一起，用人脸识别技术判断是不是同一个人。 在上一篇文章中，我们介绍了实现人脸检测的两种方法，接下来要介绍的是人脸识别，通过对比两张人脸，计算其特征相似度，来判断是否是同一个人。 人脸识别模型使用基于NN4改造的CNN模型训练和提取特征nn4.small2.v1是FaceNet论文中描述的NN4模型的变体，在OpenFace的模型列表中有nn4.small2详细介绍，具体内容点击下方链接查看https://cmusatyalab.github.io/openface/models-and-accuracies/#model-definitions 模型列表 Model Number of Parameters nn4.small2 3733968 nn4.small1 5579520 nn4 6959088 nn2 7472144 本文使用Keras版本中的一种实现，模型定义在model.pyKeras版本的github地址：https://github.com/krasserm/face-recognition Retrain人脸识别模型工作流程1、加载训练数据集2、人脸检测、对齐和提取（使用OpenFace的人脸对齐工具AlignDlib）3、人脸特征向量学习（使用预训练的nn4.small1.v1模型）4、人脸分类（使用KNN或SVM） 加载训练数据集训练集组织形式images目录中有3张图像，两张吴恩达(Andrew Ng)的照片，一张杨安泽(Andrew Yang)照片，放一起看两个人还是很像的。 最好是1:1比例，如果原图不是1:1比例，提取后的人脸会进行拉伸变换，仅支持.jpg和.jpeg两种格式。 1234567891011121314151617181920212223242526272829303132# 加载训练数据集import numpy as npimport cv2import os.pathclass IdentityMetadata(): def __init__(self, base, file): self.base = base # 数据集根目录 # self.name = name # 目录名 self.file = file # 图像文件名 def __repr__(self): return self.image_path() def image_path(self): return os.path.join(self.base, self.file) def load_metadata(path): metadata = [] for f in os.listdir(path): # 检查文件名后缀，仅支持 jpg 和 jpeg 两种文件格式 ext = os.path.splitext(f)[1] if ext == '.jpg' or ext == '.jpeg': metadata.append(IdentityMetadata(path, f)) return np.array(metadata)def load_image(path): img = cv2.imread(path, 1) # OpenCV 默认使用 BGR 通道加载图像，转换为 RGB 图像 return img[...,::-1]metadata = load_metadata('images') 人脸检测、对齐和提取从原图提取96*96RGB人脸图像。 123456789101112131415161718192021222324252627282930313233# 人脸检测、对齐和提取import matplotlib.pyplot as pltimport matplotlib.patches as patchesfrom align import AlignDlib# 初始化 OpenFace 人脸对齐工具，使用 Dlib 提供的 68 个关键点alignment = AlignDlib('landmarks.dat')# 加载一张训练图像img = load_image(metadata[0].image_path())# 检测人脸并返回边框bb = alignment.getLargestFaceBoundingBox(img)# 使用指定的人脸关键点转换图像并截取 96x96 的人脸图像aligned_img = alignment.align(96, img, bb, landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE)# 绘制原图plt.figure(1)plt.subplot(131)plt.imshow(img)plt.xticks([])plt.yticks([])# 绘制带人脸边框的原图plt.subplot(132)plt.imshow(img)plt.gca().add_patch(patches.Rectangle((bb.left(), bb.top()), bb.width(), bb.height(), fill=False, color='red'))plt.xticks([])plt.yticks([])# 绘制对齐后截取的 96x96 人脸图像plt.subplot(133)plt.imshow(aligned_img)plt.xticks([])plt.yticks([])plt.show() 人脸检测、对齐和提取的结果如下图所示 加载预训练模型nn4.small2.v1我们从 OpenFace 提供的 预训练模型 中选择 nn4.small2.v1。 这些模型使用公开数据集 FaceScrub 和 CASIA-WebFace进行训练。Keras-OpenFace 项目将这些模型文件转换为 csv 文件，然后我们将其转换为 Keras h5 模型文件 nn4.small2.v1.h5。 预训练模型 Model alignment landmarkIndices nn4.v1 openface.AlignDlib.INNER_EYES_AND_BOTTOM_LIP nn4.v2 openface.AlignDlib.OUTER_EYES_AND_NOSE nn4.small1.v1 openface.AlignDlib.OUTER_EYES_AND_NOSE nn4.small2.v1 openface.AlignDlib.OUTER_EYES_AND_NOSE nn4.small2.v1.h5、model.py、align.py这些文件可以从下面github仓库获取：https://github.com/krasserm/face-recognition 1234567891011121314151617181920# 加载预训练模型nn4.small2.v1from model import create_modelnn4_small2_pretrained = create_model()nn4_small2_pretrained.load_weights('models/nn4.small2.v1.h5')def align_image(img): return alignment.align(96, img, alignment.getLargestFaceBoundingBox(img), landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE)embedded = np.zeros((metadata.shape[0], 128))for i, m in enumerate(metadata): img = load_image(m.image_path()) img = align_image(img) # 数据规范化 img = (img / 255.).astype(np.float32) # 人脸特征向量 embedded[i] = nn4_small2_pretrained.predict(np.expand_dims(img, axis=0))[0] 计算人脸特征的欧式距离，计算相似度Squared L2 Distance(欧式距离)，计算两个向量之间的距离。 在上一步，我们获得所有测试人脸的特征向量，我们可以通过计算其之间的距离，来判断人脸的相似度，距离越小，相似度越高。 123456789101112131415161718192021222324# Squared L2 Distancedef distance(emb1, emb2): return np.sum(np.square(emb1 - emb2))count = 0def show_pair(idx1, idx2): global count count += 1 plt.figure(num=count, figsize=(8,3)) plt.suptitle(f'Distance = &#123;distance(embedded[idx1], embedded[idx2]):.2f&#125;') plt.subplot(121) plt.imshow(load_image(metadata[idx1].image_path())) plt.xticks([]) plt.yticks([]) plt.subplot(122) plt.imshow(load_image(metadata[idx2].image_path())) plt.xticks([]) plt.yticks([])show_pair(0, 1)show_pair(0, 2)show_pair(1, 2)plt.show() 从上面三张结果图我们可以看到，两个吴恩达的照片人脸特征的欧式距离为0.09，吴恩达跟杨安泽的距离为0.33。 如何利用获得的距离来判断两个张照片上的人是否是同一个人？如果距离值低于某一阈值，则认为是同一个人。 如何确定阈值，一般通过大量已标记的测试值，阈值从小到大取值，计算获得识别的准确率，取准确率比较高阈值。 我们这里阈值取0.3，则可以判断测试的人脸1、2为同一个人，3为另一个人，但两个人长得很像。 完整代码：https://github.com/HamptonChen/tensorflow-learning","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.chenhanpeng.com/categories/机器学习/"}],"tags":[{"name":"face_recognition","slug":"face-recognition","permalink":"http://www.chenhanpeng.com/tags/face-recognition/"},{"name":"人脸识别","slug":"人脸识别","permalink":"http://www.chenhanpeng.com/tags/人脸识别/"},{"name":"FaceNet","slug":"FaceNet","permalink":"http://www.chenhanpeng.com/tags/FaceNet/"}]},{"title":"20行代码实现人脸检测","slug":"20行代码实现人脸检测","date":"2019-07-22T23:27:50.000Z","updated":"2019-07-23T00:53:31.776Z","comments":true,"path":"2019/07/23/20行代码实现人脸检测/","link":"","permalink":"http://www.chenhanpeng.com/2019/07/23/20行代码实现人脸检测/","excerpt":"","text":"如今，“刷脸”已经成为人们生活中的日常，刷脸支付、人脸解锁、门禁等，都运用了人脸识别技术。人脸识别技术已广泛应用于金融、司法、公安、教育、医疗等诸多领域，同时也涌现出如：旷视科技、商汤科技等一批优秀的企业。 人脸识别算法主要分为三个流程： 人脸检测（Face Detection） 人脸对齐（Face Alignment） 人脸特征表征（Feature Representation） 本文我们主要针对人脸检测这一部分，利用OpenCV和face_recognition库分别实现图片中的人脸检测。 开发环境 Windows 10(x64) OpenCV 4.1.0.25 face_recognition 1.2.3 使用OpenCV进行人脸检测OpenCV实现人脸检测的主要思路为： 将图片转换成灰度图（降为一维的灰度，减低计算强度） 使用训练分类器查找人脸 图片上画矩形 图片转为灰度图使用OpenCV的cvtColor()方法转换图片颜色1gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) 使用训练分类器查找人脸在使用OpenCV的人脸检测之前，需要一个人脸训练模型，格式为xml。 我们这里使用OpenCV提供好的人脸分类模型xml，下载地址如下：https://github.com/opencv/opencv/tree/master/data/haarcascades 图片上画矩形使用OpenCV的rectangle()绘制矩形 检测结果 完整代码123456789101112131415161718192021222324252627282930# 使用OpenCV进行人脸检测import cv2from matplotlib import pyplot as pltimagePath = './test_face_detection.jpg'# 引入OpenCV提供的人脸分类模型xmlcascPath = './haarcascade_frontalface_default.xml'# Create the haar cascadefaceCascade = cv2.CascadeClassifier(cascPath)# 读取图像并转为灰度图image = cv2.imread(imagePath)gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)# 检测图片中的人脸faces = faceCascade.detectMultiScale( gray, scaleFactor=1.1, minNeighbors=4, minSize=(30, 30))color = (0, 255, 0)# 用矩形框将人脸框出来for (x, y, w, h) in faces: cv2.rectangle(image, (x, y), (x+w, y+h), color, 2)plt.title(\"Found &#123;0&#125; faces!\".format(len(faces)))plt.axis(\"off\")plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))plt.show() 参数说明 gray：转换的灰度图 scaleFactor：图像缩放比例，可理解为相机的x倍镜 minNeighbors：对特征检测点周边多少有效点同时检测，这样可避免因选取的特征检测点太小而导致遗漏 minSize：特征检测点的最小尺寸 使用face_recognition库进行人脸检测face_recognition库是使用Dlib最先进的面部识别功能构建而成，具有深度学习功能。该模型在LFW上的准确率为99.38%。 检测结果 从上面的结果来看，face_recognition库的检测准确率比OpenCV的高。 完整代码1234567891011121314151617181920# 使用face_recognition库进行人脸检测import face_recognitionimport cv2from matplotlib import pyplot as pltimagePath = './test_face_detection.jpg'# 使用face_recognition加载图片,并检测人脸image = face_recognition.load_image_file(imagePath)#检测图片中所有人脸face_locations = face_recognition.face_locations(image)# 用矩形框框出检测到的人脸for (top, right, bottom, left) in face_locations: cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)plt.title(\"Found &#123;0&#125; faces!\".format(len(face_locations)))plt.axis(\"off\")plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))plt.show() 识别人脸关键点调用face_recognition.face_landmarks()方法即可得到人脸特征点, 返回一个字典, 下图是返回的数据, 包括chin(下巴), left_eye(左眼)等。1&#123;'chin': [(184, 182), (187, 198), (191, 213), (196, 229), (202, 243), (211, 256), (223, 266), (236, 275), (251, 277), (267, 273), (281, 263), (295, 251), (304, 236), (308, 219), (309, 201), (311, 184), (311, 167)], 'left_eyebrow': [(192, 170), (199, 163), (210, 162), (220, 163), (231, 166)], 'right_eyebrow': [(246, 163), (258, 158), (269, 155), (281, 155), (291, 160)], 'nose_bridge': [(240, 177), (240, 187), (240, 197), (241, 208)], 'nose_tip': [(233, 217), (238, 218), (243, 219), (248, 217), (254, 215)], 'left_eye': [(205, 181), (211, 177), (219, 177), (226, 180), (219, 183), (211, 183)], 'right_eye': [(258, 177), (264, 172), (272, 172), (279, 174), (273, 178), (265, 178)], 'top_lip': [(228, 242), (234, 236), (240, 231), (245, 232), (250, 230), (258, 233), (267, 238), (263, 238), (251, 237), (246, 238), (241, 238), (232, 242)], 'bottom_lip': [(267, 238), (259, 243), (252, 247), (247, 248), (241, 248), (235, 246), (228, 242), (232, 242), (241, 239), (246, 239), (251, 238), (263, 238)]&#125; 人脸关键点检测结果 完整代码12345678910111213141516171819# 调用face_recognition.face_landmarks()方法得到人脸特征点import face_recognitionimport cv2from matplotlib import pyplot as pltimagePath = './test_face_landmarks.jpg'image = face_recognition.load_image_file(imagePath)face_landmarks_list = face_recognition.face_landmarks(image)for each in face_landmarks_list: for i in each.keys(): for any in each[i]: image = cv2.circle(image, any, 2, (0, 255, 0), 1)plt.title(\"Face landmarks\")plt.axis(\"off\")plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))plt.show() 本文只是使用OpenCV和face_recognition库进行实现简单的人脸检测，基于此我们还可以进行许多好玩的事情，比如：脸部轮廓绘制、数字化妆、头像特效合成等等。 上述人脸检测demo的github地址：https://github.com/HamptonChen/tensorflow-learning/tree/master/face_detection","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.chenhanpeng.com/categories/机器学习/"}],"tags":[{"name":"人脸检测","slug":"人脸检测","permalink":"http://www.chenhanpeng.com/tags/人脸检测/"},{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.chenhanpeng.com/tags/OpenCV/"},{"name":"face_recognition","slug":"face-recognition","permalink":"http://www.chenhanpeng.com/tags/face-recognition/"}]},{"title":"你还在用二分法求2个鸡蛋100层楼的问题吗？","slug":"interview_questions/2个鸡蛋100层楼","date":"2019-07-10T15:56:13.000Z","updated":"2019-07-10T16:05:27.115Z","comments":true,"path":"2019/07/10/interview_questions/2个鸡蛋100层楼/","link":"","permalink":"http://www.chenhanpeng.com/2019/07/10/interview_questions/2个鸡蛋100层楼/","excerpt":"","text":"题目2个鸡蛋，100层楼，如何用最少的试验次数得到在鸡蛋落下不碎的最高层数？这一据说曾被谷歌纳入校园招聘题库的经典面试题，想必许多人都曾遇到过，又有多少人与我一样，不加思索就直接回答用二分法查找的？ 但是，二分法真的是最优试验方法吗？接下来我们来分析几种解法。 首先我们先认真看一下完整的题目(之前做过这道题的同学可以跳过这一步)： 原题：两个软硬程度一样但未知的鸡蛋，它们有可能都在一楼扔下来就摔碎，也有可能从100层楼上扔下来也没事。有座100层的楼，要你用这两个鸡蛋确定哪一层是鸡蛋可以安全落下的最高位置。可以摔碎两个鸡蛋，在最坏情况下，如何用最少的试验次数得到鸡蛋落下不会被摔碎的最高层数？ 解法最笨的方法：遍历查找把其中的一个鸡蛋，从第1层开始往下扔。如果第一层没碎，换到第2层扔；如果第2层没碎，换到第3层扔…假设第50层没碎，第51层碎了，说明鸡蛋落下不会摔碎的最高层数为第50层。 这个方法在最坏情况下，需要扔99次。 二分法采用二分查找的方法： 把第一个鸡蛋从一半楼层(50层)扔下。 如果鸡蛋碎了，则第二个鸡蛋就从第1层开始扔，一层一层增长，直到49层。 如果第一枚鸡蛋在50层没有被摔碎，则继续使用二分法，从剩余的楼层的一半(75层)开始往下扔… 在最坏情况下，这种二分法需要进行50次试验0。 平方根法如何让第一个鸡蛋和第二个鸡蛋的尝试次数尽可能均衡？我们做一个平方根运算，100的平方根为10。 因此我们第一个鸡蛋每10层扔一次，第一次从第10层扔，没碎的话再加10层，即从20层扔….一直扔到100层。 第二个鸡蛋从第一个鸡蛋碎掉的n层往下9层，即n-9层开始一层一层往上试。 这种方法最好的情况为：第一个鸡蛋在第10层碎掉，尝试次数 1 + 9 = 10 次。 最坏的情况为：第一个鸡蛋在第100层碎掉，尝试次数为 10 + 9 = 19 次。 这样子看来平方根的方法算是比较好的方法，那么还有更好的方法吗？ 反向思考我们反向思考一下这个题目：假设题目存在最优解，这个最优解的最坏情况尝试x次，那么我们第一次扔要选择在第几层？ 假设第一次扔在x+1层：如果第一个鸡蛋碎了，那么第二个鸡蛋就只能从第1层开始一层一层扔，一直扔到第x层。这样总共尝试了x+1次，与最优解的尝试x次相悖。 假设第一次在x-1层：如果第一个鸡蛋碎了，那么第2个鸡蛋就要从第1层开始扔，一直到x-2层，共尝试了x-2+1=x-1次，虽然没有超出假设次数，但似乎有些过于保守。 假设第一次扔在第x层： 如果第一个鸡蛋碎了，那么第二个鸡蛋只能从第1层开始一层一层扔，一直扔到第x-1层。这样，我们总共尝试了x-1+1 = x次，刚刚好没有超出假设次数。 恰恰是从第x层开始扔，选择高一层或第一层都不合适。 如果第一个鸡蛋没碎，问题就变成了：在100-x层楼往下扔，要求尝试次数不超过x-1次。 那么第二次的尝试次数的上限变为x-1次，所以第2次试验的楼层跨度为x-1层，真实层数为x+x-1层。 以此类推我们可以列出楼层的方程式： x + (x - 1) + (x - 2) + … + 1 = 100 接下来就是求解方程式，我们将这种方法称为解方程法： 解方程法x + (x - 1) + (x - 2) + … + 1 = 100 =&gt; (x + 1) * x / 2 = 100 向上取整得到x=14 即最优解的最坏尝试次数为14次，第1个鸡蛋开始扔的层数也为14层。 第一个鸡蛋没碎的情况下，所尝试的楼层为：14， 27， 39， 50， 60， 69， 77， 84， 90， 95， 99， 100 假设鸡蛋不会被摔碎的最高楼层为55层，那么第一个鸡蛋尝试的楼层为14，27,39,50,60，在第60层碎了； 第二个鸡蛋从51层开始， 51,52,53,54,55,56，第56层碎了，则尝试次数为5 + 6 = 11 &lt; 14 这道面试题的解法到此到一段落，现在你还会认为二分法是这道题的最优解吗？ 其实这道题还可以衍生下面的问题：总共有M层楼，N个鸡蛋，要找到鸡蛋不被摔碎的最高楼层，需要尝试几次？ 这个问题就不在这里展开讨论了，大家可以自行尝试求解。","categories":[{"name":"面试题目","slug":"面试题目","permalink":"http://www.chenhanpeng.com/categories/面试题目/"}],"tags":[{"name":"面试题目","slug":"面试题目","permalink":"http://www.chenhanpeng.com/tags/面试题目/"},{"name":"2个鸡蛋100层楼","slug":"2个鸡蛋100层楼","permalink":"http://www.chenhanpeng.com/tags/2个鸡蛋100层楼/"}]},{"title":"微信小程序使用otp算法踩坑总结","slug":"bug_summary/微信小程序使用otp算法踩坑总结","date":"2019-07-09T14:13:05.000Z","updated":"2019-07-09T14:22:43.519Z","comments":true,"path":"2019/07/09/bug_summary/微信小程序使用otp算法踩坑总结/","link":"","permalink":"http://www.chenhanpeng.com/2019/07/09/bug_summary/微信小程序使用otp算法踩坑总结/","excerpt":"","text":"背景前两天项目有个类似动态口令的功能要实现，团队最终决定使用OTP算法来实现：前端先向后端请求获取用户的密钥(secret)，将之保存在缓存中，之后前端根据该secret，使用OTP算法中的TOTP方式生成6位动态密码，将6位动态密码传到后台验证。 OTP1.1 简介OTP(One-Time-Password)：一次性密码，也称为动态口令。是使用密码技术实现的在客户端和服务端之间通过共享密钥的一种认证技术，是一种强认证技术，是增强目前静态密码口令认证的一种非常方便的技术手段，是一种重要的双因素认证技术。 1.2 OTP认证原理动态口令的基本认证原理是在认证双方共享密钥，也称种子密钥，并使用同一个种子密钥对某一个事件计数、或时间值、或异步挑战数进行密码算法计算，使用的算法有对称算法、HASH、HMAC，之后比较计算值是否一致进行认证。可以做到一次一个动态口令，使用后作废，口令长度通常为6-8个数字，使用方便，与通常的静态口令认证方式类似。 1.3 OTP实现方式 时间同步(TOTP) 事件同步(HOTP) 挑战/应答(OCRA) 本文内容主要是小程序使用OTP算法踩坑总结，不对OTP算法的三种实现方式的工作原理进行详细介绍，有兴趣的朋友自行查找相关资料。 踩坑记录2.1 后端使用的otp库说明opt算法有许多现成的库可以直接调用，后端使用的是aerogear-otp-java这个库，问题不在后端，这里就不对这个库进行讲解，有兴趣的朋友可以自己查看：github地址： https://github.com/aerogear/aerogear-otp-java 2.2 踩坑前提我们的微信小程序项目目前不支持引用第三方的npm包，所以要使用第三方的js库，需要将其js文件下载放到小程序目录中，通过require去引入。还有一点就是小程序项目还不支持node.js，如果js库有相关的node.js代码，还需要做一些改造。以上两点背景给我挖了一个大坑往里跳。 2.3 跳入第一个坑我们先找可用的otp的js库，上github一搜，还是很多的，先选一个start数量比较的的：https://github.com/yeojz/otplib。 我们现在node.js环境上对 otplib 这个进行测试：123456const authenticator = require('otplib/authenticator');const crypto = require('crypto');authenticator.options = &#123; crypto &#125;;const secret = 'BYYHJ5R6C3DNZJX3'const token = authenticator.generate(secret);console.log(token); 执行上面的代码，可以获得6位动态密码，拿到后端验证，验证不通过…各种尝试和排查后，放弃了，这个库和后端的aerogear-otp-java不兼容，尴尬。。。 2.4 跳入第二个坑又到github上一通找，各种尝试，终于找到一个可以与aerogear-otp-java兼容的js库：node-lib-otpgithub地址： https://github.com/JCloudYu/node-lib-otp 12345const otp = require( 'lib-otp' );let otpObj = otp(&#123; secret:'BYYHJ5R6C3DNZJX3'&#125;);console.log(otpObj.totp(6)); 将生成的6位动态密码传到后台验证，通过。 心想终于找到能用的了，有种胜利就在眼前的喜悦，马不停蹄下载相关js，着手修改其中的node.js代码，改到一半发现该库引用了太多node.js的写法和库，短时间内无法完成修改并保证可用，放弃该库了。。。 2.5 出坑在github上搜索许久仍旧未找到合适的js库，突然灵光一闪上码云找一下，搜索结果第一个superzlc/otp有写小程序，尝试一下。地址：https://gitee.com/superzlc/otp/tree/master下载js，引入该库生成动态密码1234const otp = require('./libs/otp')const TOTP = otp.TOTPconst token = new TOTP('BYYHJ5R6C3DNZJX3', 3, 30).gen()console.log(token) 验证通过，还不用修改代码，终于爬出坑了。 总结OTP算法中的TOTP方式生成6位动态密码可用库如下： 后端java ： https://github.com/aerogear/aerogear-otp-java node.js: https://github.com/JCloudYu/node-lib-otp 小程序纯js：https://gitee.com/superzlc/otp/tree/master 注意点：前后端的计数值应一致，否则无法验证通过","categories":[{"name":"问题总结","slug":"问题总结","permalink":"http://www.chenhanpeng.com/categories/问题总结/"}],"tags":[{"name":"otp算法","slug":"otp算法","permalink":"http://www.chenhanpeng.com/tags/otp算法/"},{"name":"小程序","slug":"小程序","permalink":"http://www.chenhanpeng.com/tags/小程序/"}]},{"title":"PDF.js实现在线展示pdf文件","slug":"PDFJS实现在线展示PDF文件","date":"2019-06-27T16:03:24.000Z","updated":"2019-07-01T00:38:12.537Z","comments":true,"path":"2019/06/28/PDFJS实现在线展示PDF文件/","link":"","permalink":"http://www.chenhanpeng.com/2019/06/28/PDFJS实现在线展示PDF文件/","excerpt":"","text":"背景现在很多项目开发过程中都会碰到PDF在线预览的需求，对于PC端浏览器，一般直接提供PDF文件，iframe一下就可以直接预览。但在移动端要预览PDF则较为麻烦，有些浏览器检测到文件流，就会直接下载，无法实现预览功能。 PDFJS就是解决这一问题比较好用的一款插件。 PDF.jsPDF.js是一个使用HTML5构建的可移植文档格式库。 PDF.js官网：http://mozilla.github.io/pdf.js/ 官网给出的使用方法是将PDF.js下载到项目静态资源目录中，在html文件中引入pdf.js去使用，但这样会导致最后项目编译打包后的资源包比较大。 pdfjs-dist这一node库这好可以解决我们的问题。pdfjs-dist是pdf.js源代码的预构建版本，我们直接在项目中引入该库即可使用，接下来我们介绍如何使用。 需要预览的PDF一般是后台接口返回的base64编码数据或者是本地上传获取到文件，接下来我们在vue工程上实现本地上传PDF文件，获取文件的base64编码，利用pdf.js实现预览效果。 基于Vue工程实现PDF在线预览1、安装pdfjs-dist依赖1npm install pdfjs-dist 2、初始化PDF，核心代码123456789101112131415161718192021222324252627282930313233343536373839previewPDF() &#123; // 引入pdf.js的字体 let CMAP_URL = 'https://unpkg.com/pdfjs-dist@2.0.943/cmaps/' //读取base64的pdf流文件 let loadingTask = pdfJS.getDocument(&#123; data: this.pdfData, // PDF base64编码 cMapUrl: CMAP_URL, cMapPacked: true &#125;) loadingTask.promise.then((pdf) =&gt; &#123; this.loadFinished = true let numPages = pdf.numPages let pageNumber = 1 this.getPage(pdf, pageNumber, numPages) &#125;)&#125;,getPage(pdf, pageNumber, numPages) &#123; let _this = this pdf.getPage(pageNumber) .then((page) =&gt; &#123; // 获取DOM中为预览PDF准备好的canvasDOM对象 let canvas = this.$refs.myCanvas let viewport = page.getViewport(_this.scale) canvas.height = viewport.height canvas.width = viewport.width let ctx = canvas.getContext('2d') let renderContext = &#123; canvasContext: ctx, viewport: viewport &#125; page.render(renderContext).then(() =&gt; &#123; pageNumber += 1 if (pageNumber &lt;= numPages) &#123; _this.getPage(pdf, pageNumber, numPages) &#125; &#125;) &#125;)&#125; 3、效果 4、注意点当PDF文件中有中文的情况下，在引用pdfjs过程中可能会出现中文不显示问题，在console中会报下面的错误，1Warning: The CMap \"baseUrl\" parameter must be specified, ensure that the \"cMapUrl\" and \"cMapPacked\" API parameters are provided. 主要原因是有pdf不支持的字体格式，可以通过引入pdf.js的字体来解决该问题。12345678// 引入pdf.js的字体let CMAP_URL = 'https://unpkg.com/pdfjs-dist@2.0.943/cmaps/'//读取base64的pdf流文件let loadingTask = pdfJS.getDocument(&#123; data: this.pdfData, // PDF base64编码 cMapUrl: CMAP_URL, cMapPacked: true&#125;) 完整代码获取：https://github.com/HamptonChen/hampton-demo-repo/tree/master/example-project","categories":[{"name":"前端","slug":"前端","permalink":"http://www.chenhanpeng.com/categories/前端/"}],"tags":[{"name":"pdf.js","slug":"pdf-js","permalink":"http://www.chenhanpeng.com/tags/pdf-js/"},{"name":"在线预览PDF文件","slug":"在线预览PDF文件","permalink":"http://www.chenhanpeng.com/tags/在线预览PDF文件/"}]},{"title":"利用TensorFlow Object Detection API实现图片和视频物体检测","slug":"利用TensorFlow Object Detection API实现图片和视频物体检测","date":"2019-06-21T15:50:14.000Z","updated":"2019-06-21T15:58:57.701Z","comments":true,"path":"2019/06/21/利用TensorFlow Object Detection API实现图片和视频物体检测/","link":"","permalink":"http://www.chenhanpeng.com/2019/06/21/利用TensorFlow Object Detection API实现图片和视频物体检测/","excerpt":"","text":"TensorFlow Object Detection API介绍物体检测是检测图片或视频中所出现的全部物体，并用矩形进行标注，物体的类别可以包括多种，比如：人、车、动物等等，即正确的答案可以是多个。 TensorFlow提供了用于检测图片或视频中所包含物体的接口(Object Detection API)，具体详情可参考下面链接：https://github.com/tensorflow/models/tree/master/research/object_detection 这个API是用COCO数据集 (http://cocodataset.org/#home) 训练出来的，是一个大型的、丰富的物体检测，分割和字幕数据集,大约有30万张图像、90种最常见物体。 这个API提供了多种不同的，使用者可以通过设置不同检测边界范围来平衡运行速度和准确率。 图中的mAP（平均精度）是检测边界框的准确率和召回率的乘积。这是一个很好的混合测度，在评价模型对目标物体的敏锐度和它是否能很好避免虚假目标中非常好用。mAP值越高，模型的准确度越高，但运行速度会相应下降。 实现物体检测环境本文代码运行环境：Python3.6、jupyter notebook 首先安装相关依赖包1234567pip install jupyterpip install tensorflowpip install pillow pip install lxmlpip install matplotlibpip install numpypip install opencv-python 图片物体检测:1、加载库1234import numpy as npimport tensorflow as tfimport matplotlib.pyplot as pltfrom PIL import Image 2、从utils模块引入label_map_util和visualization_utilslabel_map_util用于后面获取图像标签和类别，visualization_utils用于可视化12from utils import label_map_utilfrom utils import visualization_utils as vis_util 3、加载预训练好的模型模型下载地址：https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md这里我们选用最轻量级的模型(ssd_mobilenet_v1_coco)。1234567891011PATH_TO_CKPT = 'ssd_mobilenet_v1_coco_2018_01_28/frozen_inference_graph.pb'PATH_TO_LABELS = 'data/mscoco_label_map.pbtxt'NUM_CLASSES = 90detection_graph = tf.Graph()with detection_graph.as_default(): od_graph_def = tf.GraphDef() with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid: od_graph_def.ParseFromString(fid.read()) tf.import_graph_def(od_graph_def, name='') 4、加载分类标签数据123label_map = label_map_util.load_labelmap(PATH_TO_LABELS)categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)category_index = label_map_util.create_category_index(categories) 5、核心代码：一个将图片转为数组的辅助函数，以及测试图片路径，使用模型进行物体检测：123456789101112131415161718192021222324def load_image_into_numpy_array(image): (im_width, im_height) = image.size return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)TEST_IMAGE_PATHS = ['test_data/image1.jpg']with detection_graph.as_default(): with tf.Session(graph=detection_graph) as sess: image_tensor = detection_graph.get_tensor_by_name('image_tensor:0') detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0') detection_scores = detection_graph.get_tensor_by_name('detection_scores:0') detection_classes = detection_graph.get_tensor_by_name('detection_classes:0') num_detections = detection_graph.get_tensor_by_name('num_detections:0') for image_path in TEST_IMAGE_PATHS: image = Image.open(image_path) image_np = load_image_into_numpy_array(image) image_np_expanded = np.expand_dims(image_np, axis=0) (boxes, scores, classes, num) = sess.run( [detection_boxes, detection_scores, detection_classes, num_detections], feed_dict=&#123;image_tensor: image_np_expanded&#125;) vis_util.visualize_boxes_and_labels_on_image_array(image_np, np.squeeze(boxes), np.squeeze(classes).astype(np.int32), np.squeeze(scores), category_index, use_normalized_coordinates=True, line_thickness=8) plt.figure(figsize=[12, 8]) plt.imshow(image_np) plt.show() 检测结果如下： 视频物体检测使用cv2读取视频并获取每一帧图片，然后将检测后的每一帧写入新的视频文件。 实现代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import numpy as npimport tensorflow as tfimport cv2from utils import label_map_utilfrom utils import visualization_utils as vis_utilcap = cv2.VideoCapture('test_data/test_video.mp4')ret, image_np = cap.read()out = cv2.VideoWriter('output_video.mp4', -1, cap.get(cv2.CAP_PROP_FPS), (image_np.shape[1], image_np.shape[0]))PATH_TO_CKPT = 'ssd_mobilenet_v1_coco_2018_01_28/frozen_inference_graph.pb'PATH_TO_LABELS = 'data/mscoco_label_map.pbtxt'NUM_CLASSES = 90detection_graph = tf.Graph()with detection_graph.as_default(): od_graph_def = tf.GraphDef() with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid: od_graph_def.ParseFromString(fid.read()) tf.import_graph_def(od_graph_def, name='') label_map = label_map_util.load_labelmap(PATH_TO_LABELS)categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)category_index = label_map_util.create_category_index(categories)with detection_graph.as_default(): with tf.Session(graph=detection_graph) as sess: image_tensor = detection_graph.get_tensor_by_name('image_tensor:0') detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0') detection_scores = detection_graph.get_tensor_by_name('detection_scores:0') detection_classes = detection_graph.get_tensor_by_name('detection_classes:0') num_detections = detection_graph.get_tensor_by_name('num_detections:0') while cap.isOpened(): ret, image_np = cap.read() if len((np.array(image_np)).shape) == 0: break image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB) image_np_expanded = np.expand_dims(image_np, axis=0) (boxes, scores, classes, num) = sess.run([detection_boxes, detection_scores, detection_classes, num_detections], feed_dict=&#123;image_tensor: image_np_expanded&#125;) vis_util.visualize_boxes_and_labels_on_image_array(image_np, np.squeeze(boxes), np.squeeze(classes).astype(np.int32), np.squeeze(scores), category_index, use_normalized_coordinates=True, line_thickness=8) out.write(cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)) cap.release()out.release()cv2.destroyAllWindows() 检测效果 至此我们利用tensorflow提供的物体检测API，实现了图片和视频的物体检测。 完整的代码和检测后的视频，请至github查看：https://github.com/HamptonChen/tensorflow-learning","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.chenhanpeng.com/categories/机器学习/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://www.chenhanpeng.com/tags/TensorFlow/"},{"name":"物体检测","slug":"物体检测","permalink":"http://www.chenhanpeng.com/tags/物体检测/"}]},{"title":"TensorFlow基础概念","slug":"TensorFlow基础概念","date":"2019-06-11T15:25:14.000Z","updated":"2019-06-11T15:29:26.714Z","comments":true,"path":"2019/06/11/TensorFlow基础概念/","link":"","permalink":"http://www.chenhanpeng.com/2019/06/11/TensorFlow基础概念/","excerpt":"","text":"TensorFlow是一个采用数据流图（data flow graphs），用于数值计算的开源软件库。 TensorFlow 是Google第二代大规模分布式深度学习框架。 灵活通用的深度学习库 端云结合的人工智能引擎 高性能的基础平台软件 跨平台的机器学习系统 应用场景： 行人检测、人脸检测、行为识别、身份证自动输入与人脸图像比较、OCR+自动化审核 TensorFlow 数据流图介绍TensorFlow数据流图是一种声明式编程范式 声明式编程与命令式编程的多角度对比 数据流图由有向边和节点组成 数据流图的优势：快 并行计算快 分布式计算快(CPUs,GPUs,TPUs) 预编译优化(XLA) 可移植性好(Language-independent representation) 张量(Tensor)在数学里，张量是一种几何实体，广义上表示任意形式的“数据”。张量可以理解为0阶（rank）标量、1阶向量和2阶矩阵在高维度空间上的推广，张量的阶描述它表示数据的最大维度。 在TensorFlow中，张量表示某种相同的数据类型的多维数组因此，张量有两个重要的属性： 1、数据类型，如浮点型、整型、字符串 2、数组形状： 各个维度的大小 TensorFlow张量是什么可以总结为一下几点： 张量是用来表示多维数据的 张量是执行操作时的输入或输出数据 用户通过执行操作来创建或计算张量 张量的形状不一定在编译时确定，可以在运行时通过形状推断计算得到 几类比较特别的张量，由以下操作产生：123tf.constant // 常量tf.placeholder // 占位符tf.Variable // 变量 变量(Variable)变量Variable是一种特殊的张量，主要作用是维护特定节点的状态，如深度学习或机器学习的模型参数。 tf.Variable方法是操作，返回值是变量（特殊张量） 通过tf.Variable方法创建的变量，与张量一样，可以作为操作的输入和输出。 不同之处： 张量的生命周期通常随依赖的计算完成而结束，内存也随即释放 变量则常驻内存，在每一步训练时不断更新值，以实现模型参数的更新。 TensorFlow变量使用流程 操作(Operation)TensorFlow用数据流图表示算法模型。数据流图由节点和有向边组成，每个节点均对应一个具体的操作。因此，操作是模型功能的实际载体。 数据流图中的节点按照功能不同可以分为3种： 存储节点：有状态的变量操作，通常用来存储模型参数 计算节点：无状态的计算或控制操作，主要负责算法逻辑表达或流程控制。 数据节点：数据的占位符操作，用于描述图外输入数据的属性。 操作的输入和输出是张量或操作（函数式编程） TensorFlow典型计算和控制操作 TensorFlow占位符操作tensorflow 使用占位符操作表示图外输入的数据，如训练数据和测试数据。 TensorFlow数据流图描述了算法模型的计算拓扑，其中的各个操作(节点)都是抽象的函数映射或数学表达式。 换句话说，数据流图本身是一个具有计算拓扑和内部结构的“壳”。在用户向数据流图填充数据前，图中并没有真正执行任何计算。 会话(Session)会话提供了估算张量和执行操作的运行环境，它是发放计算任务的客户端，所有计算任务都由它连接的执行引擎完成。一个会话的典型使用流程分为以下3步：1234567# 1、创建会话# target:会话连接的执行引擎 graph:会话加载的数据流图 config:会话启动时的配置项sess = tf.Session(target=..., graph=..., config=...)# 2、估算张量或执行操作sess.run(...)# 3、关闭会话sess.close() 会话执行获取张量值的另外两种方法：估算张量(Tensor.eval)与执行操作(Operation.run) 12345678910import tensorflow as tf# 创建数据流图：y=w * x + b, 其中w和b为存储节点，x为数据节点x = tf.placeholder(tf.float32)w = tf.Variable(1.0)b = tf.Variable(1.0)y = w * x + bwith tf.Session() as sess: tf.global_variables_initializer().run() # Operation.run fetch = y.eval(feed_dict=&#123;x: 3.0&#125;) # Tensor.eval print(fetch) # fetch = 1.0 * 3.0 + 1.0 会话执行原理当我们调用sess.run(train_op)语句执行训练操作时： 首先，程序内部提取操作依赖的所有前置操作。这些操作的节点共同组成一幅子图。 然后，程序会将子图中的计算节点、存储节点和数据节点按照各自的执行设备分类，相同设备上的节点组成了一幅局部图 最后，每个设备上的局部图在实际执行时，根据节点间的依赖关系将各个节点有序地加载到设备上执行。 优化器(Optimizer)优化器是实现优化算法的载体。 一次典型的迭代优化应该分为以下3个步骤： 1、计算梯度：调用compute_gradients方法; 2、处理梯度：用户按照自己需求处理梯度值，如梯度裁剪和梯度加权等。 3、应用梯度：调用apply_gradients方法，将处理后的梯度值应用到模型参数。 TensorFlow内置优化器：","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.chenhanpeng.com/categories/机器学习/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://www.chenhanpeng.com/tags/TensorFlow/"}]},{"title":"CF-基于协同过滤的推荐算法","slug":"CF-基于协同过滤的推荐算法","date":"2019-05-13T15:05:11.000Z","updated":"2019-06-12T01:20:54.845Z","comments":true,"path":"2019/05/13/CF-基于协同过滤的推荐算法/","link":"","permalink":"http://www.chenhanpeng.com/2019/05/13/CF-基于协同过滤的推荐算法/","excerpt":"","text":"概述上一篇文章我们介绍了CB推荐算法，本篇文章我们将介绍另外一种推荐算法——基于协同过滤的推荐算法(Collaborative Filtering Recommendations)，下文我们统一简称为CF算法。 协同过滤推荐算法作为推荐算法中最经典的类型，包括在线的协同和离线的过滤两部分。在线协同是指通过在线数据找到用户可能喜欢的物品，离线过滤则是过滤掉一些不值得推荐的数据，比如推荐评分低的，或者推荐评分高但用户已经购买过的数据。 CF算法的数据源是基于用户历史行为和物品的矩阵数据，即UI（User-Item）矩阵数据。CF算法一般可以分为基于用户（User-Based）的协同过滤和基于物品（item-based）的协同过滤。 算法原理1、 User-Based CF假设： 用户喜欢跟他过去喜欢的物品相似的物品 历史上相似的物品在未来也相似 方法： 给定用户u，找到他过去喜欢的物品的集合R(u) 把和R(u)相似的物品推荐给u 2、 Item-Based CF假设： 用户喜欢跟他过去喜欢的物品相似的物品 历史上相似的物品在未来也相似 方法： 给定用户u，找到他过去喜欢的物品的集合R(u) 把和R(u)相似的物品推荐给u CF算法优缺点优点： 充分利用群体智慧 推荐精度高于CB 利于挖掘隐含的相关性 缺点： 推荐结果解释性较差 对时效性强的Item不适用 冷启动问题 算法处理过程1、数据准备用户user_id,物品item_id，打分score（score可以是用户对某件物品的评分，或是根据用户行为计算出的偏好度得分，比如曝光、点击、收藏的加权得分，具体权重可以参考漏斗模型），数据如下： user_id item_id score id1 item1 3 id1 item2 2 id2 item1 4 id2 item2 3 2、计算相似性矩阵CF算法的关键在于计算获得user或item的相似度矩阵，即UU矩阵和II矩阵。 User-Based： 用户之间的相似度计算，是基于对相同的物品打过分，可以将各个分值联合起来作为一个向量，然后计算余弦相似度： Item-Based： 计算各个Item之间的相似度矩阵，即对两个Item都打过分的id的打分情况作为向量，同理得到item的相似度矩阵。 3、推荐根据相似度矩阵，选择与目标用户相似度最高的几位用户，在第一张表中选取各自打分较高的物品，形成一个推荐候选集合，准备推荐给目标用户。 User-Based CF和Item-Based CF区别通过两种方法，我们发现两种的分数不一样，那么该用哪个呢，哪个真实，其实这个不重要，生活中我们一般是基于用户给用户推荐Top问题，而不是打分情况，即只要排好序就可以，工作这个分数其实还是有用的，一般我们有这么个准则，哪个维度小用哪个，电商网站物品的矩阵远大于用户矩阵，规模太大有时候造成一些慢，相反一样 那么我们来看一下这两个对比不同 User-Based Item-Based 性能 适用用户较少场合，如果用户多，计算用户相似矩阵代价太大 适用于物品数明显小于用户数的场合，如果物品很多，计算物品相似度矩阵代价很大 领域 时效性强，用户个性化兴趣不太明显的领域 长尾物品丰富，用户个性化需求强烈的领域 实时性 用户有新行为，不一定造成推荐结果立即变化 用户有新行为，一定会导致推荐结果的实时变化 冷启动 在新用户对很少的物品产生行为后，不能立即对他进行个性化推荐，因为用户相似度表是每隔一段时间离线计算的 新物品上线后一段时间，一旦有用户对物品产生行为，就可以将新物品推荐给对它产生行为的用户兴趣相似的其他用户 新用户只要对一个物品产生行为，就可以给他推荐和该物品相关的其他物品 但没有办法在不离线更新物品相似度表的情况下将新物品推荐给用户 推荐理由 很难提供令用户信服的推荐解释 利用用户的历史行为给用户做推荐解释，可以令用户比较信服","categories":[{"name":"大数据","slug":"大数据","permalink":"http://www.chenhanpeng.com/categories/大数据/"}],"tags":[{"name":"推荐算法","slug":"推荐算法","permalink":"http://www.chenhanpeng.com/tags/推荐算法/"},{"name":"大数据","slug":"大数据","permalink":"http://www.chenhanpeng.com/tags/大数据/"}]},{"title":"CB-基于内容的推荐算法","slug":"CB-基于内容的推荐算法","date":"2019-05-07T15:57:25.000Z","updated":"2019-06-12T01:20:57.186Z","comments":true,"path":"2019/05/07/CB-基于内容的推荐算法/","link":"","permalink":"http://www.chenhanpeng.com/2019/05/07/CB-基于内容的推荐算法/","excerpt":"","text":"在推荐系统领域，一般主要有两种推荐任务：评分预测和Top-N推荐。下面我们简单介绍一下这两种推荐任务： 评分预测：我们以音乐推荐系统为例，首先用户A和用户B都对某几首歌进行喜欢程度打分，假设两个用户对周杰伦的《稻香》和陈奕迅的《好久不见》有相同的喜欢程度，且打分都不低，那么我们是否可以预测这两个用户有相同的爱好，那么我们可以将用户A喜欢的《青花瓷》这首歌推荐给用户B。 Top-N推荐假设用户A喜欢的音乐列表里有《十年》、《好久不见》、《稻香》，用户B喜欢的音乐列表里有《同桌的你》、《三国杀》、《逆战》，假设用户C刚开始使用该系统，并将《稻香》添加到喜欢的音乐中，那么我们是不是可以先推荐与用户C喜好相近的用户A喜欢的音乐给用户C，再推荐用户B喜欢的音乐。先推荐关联性高的，将关联性低的放在后面，这就是Top-N推荐。 基于内容的推荐算法(CB)今天要介绍的CB(Content-Based Recommendations)算法是众多推荐推荐算法中的一种，也是比较早被使用的一种推荐算法。 1、引入Item属性的基于内容的推荐用户喜欢歌曲A(item)，现在有一首新歌曲B，如何确定是否要推荐给用户？ 首先我们对所有的音乐进行内容分析和item内容属性索引，即进行特征建立和建模，音乐的特征有：作者、年代、音乐风格等等。 然后我们去计算歌曲A和歌曲B两者的相关性，如何相关性高，则将歌曲B推荐给用户。 这类推荐算法有以下优缺点： 优点： 提升推荐结果的相关性 结果可解释 推荐结果容易被用户感知 缺点： 无个性化 依赖于对item的深度分析 2、引入User属性的基于内容的推荐引入User属性的基于内容推荐算法加入了用户行为分析和建立用户兴趣模型。假设用户在过去的一段时间里听了爵士乐、DJ、周杰伦的歌，我们可以根据这几个历史标签进行数据建模，建立历史标签的正排倒排的内容分析。与上面不同的是这方面是基于用户的历史行为作分析，我们将其存到数据库，以后为用户推荐音乐时，先查库，然后进行相关的推荐。 这类推荐算法有以下优缺点： 优点： 用户模型刻画了用户兴趣需求 推荐形式多样，具有个性化 结果可解释 缺点： 推荐精度低 马太效应 用户行为稀疏导致覆盖率低","categories":[{"name":"大数据","slug":"大数据","permalink":"http://www.chenhanpeng.com/categories/大数据/"}],"tags":[{"name":"推荐算法","slug":"推荐算法","permalink":"http://www.chenhanpeng.com/tags/推荐算法/"},{"name":"大数据","slug":"大数据","permalink":"http://www.chenhanpeng.com/tags/大数据/"}]},{"title":"Vue-CLI3 环境变量和模式","slug":"vue-cli3-环境变量和模式","date":"2019-04-29T14:46:30.000Z","updated":"2019-08-27T06:40:29.409Z","comments":true,"path":"2019/04/29/vue-cli3-环境变量和模式/","link":"","permalink":"http://www.chenhanpeng.com/2019/04/29/vue-cli3-环境变量和模式/","excerpt":"","text":"前段时间工作中用Vue-CLI3构建的Vue工程一些静态资源，比如静态H5页面、图片、图标等等，我们一般放在固定的一些服务器上，链接前缀一般相对固定，但我们打包发布一般要区分测试环境和生产环境，此时的静态资源路径也需要区分测试和生产，如果每次打包都要根据部署的环境去修改路径十分麻烦，这时候vue-cli的模式和环境变量则能够很好地解决这个麻烦。 模式模式是Vue CLI项目中一个重要的概念。默认情况下，一个Vue CLI项目有三个模式： development 模式用于vue-cli-service serve production 模式用于vue-cli-service build和vue-cli-service test:e2e test 模式用于vue-cli-service test:unit 模式不同于NODE_ENV，一个模式可以包含多个环境变量。每个模式都会将NODE_ENV的值设置为模式的名称，比如：development模式下NODE_ENV的值会被设置为development 当然，我们也可以通过为.env文件增加后缀来设置某个模式下特有的环境变量。 示例：test模式我们在项目根目录下创建一个名为.env.test和.env的文件 12// .env文件：VUE_APP_TITLE=VUE-CLI3-DEMO 123// .env.test文件NODE_ENV=productionVUE_APP_TITLE=VUE-CLI3-DEMO(test) vue-cli-service build 会加载可能存在的 .env、.env.production 和 .env.production.local 文件然后构建出生产环境应用； vue-cli-service build –mode test 会在 staging 模式下加载可能存在的 .env、.env.test 和 .env.test.local 文件然后构建出生产环境应用。 这两种情况下，根据 NODE_ENV，构建出的应用都是生产环境应用，但是在 test 版本中，process.env.VUE_APP_TITLE 被覆写成了另一个值。 我们在vue.config.js文件中添加console.log(process.env.VUE_APP_TITLE) 在package.json文件中添加”build-test”: “vue-cli-service build –mode test” 执行npm run build和npm run build-test 通过查看控制台打印出的分别是VUE-CLI3-DEMO和VUE-CLI3-DEMO(test)，由此可见不同模式下的环境变量不同。 环境变量只有以VUE_APP_开头的变量才会被webpack.DefinePlugin静态嵌入到客户端侧的包中，我们可以在代码中以下面的方式访问：process.env.VUE_APP_TITLE 除了VUE_APP_*变量外，还有两个始终可用的特殊变量： NODE_ENV 值为development、productin、test中的一个。 BASE_URL 与vue.config.js中的publicPath相符，即应用部署的基础路径 回到我们最开始的关于静态资源在不同环境下的路径问题，我们可以分别创建.env.test和.env.production两个文件，在文件中添加变量VUE_APP_STATIC_BASE_URL，根据不同环境赋予不同的值，在代码中用到静态资源的时候通过process.env.VUE_APP_STATIC_BASE_URL + 静态资源后续具体路径，再package.json中添加相应的模式打包命令，这样就可以比较好解决我们最开始提出的问题了。","categories":[{"name":"前端","slug":"前端","permalink":"http://www.chenhanpeng.com/categories/前端/"},{"name":"Vue","slug":"前端/Vue","permalink":"http://www.chenhanpeng.com/categories/前端/Vue/"}],"tags":[{"name":"Vue-CLI3","slug":"Vue-CLI3","permalink":"http://www.chenhanpeng.com/tags/Vue-CLI3/"},{"name":"模式","slug":"模式","permalink":"http://www.chenhanpeng.com/tags/模式/"},{"name":"环境变量","slug":"环境变量","permalink":"http://www.chenhanpeng.com/tags/环境变量/"}]},{"title":"中文分词Python库介绍","slug":"中文分词Python库介绍","date":"2019-04-21T09:05:40.000Z","updated":"2019-04-27T11:56:12.005Z","comments":true,"path":"2019/04/21/中文分词Python库介绍/","link":"","permalink":"http://www.chenhanpeng.com/2019/04/21/中文分词Python库介绍/","excerpt":"","text":"在前面的文章《中文分词》一文中，我们简单介绍了中文分词及其常用的分词方法，本文将介绍几个比较有代表性的支持中文分词的python库。本文所有实例均基于python3.6环境运行。 jieba结巴分词：使用较为广泛的一款python分词工具，专用于分词的python库，分词效果较好。 GitHub： https://github.com/fxsjy/jieba 特点： 支持三种分词模式：1、精确模式：试图将句子最精确地切开，适合文本分析2、全模式：把句子中所有的可以成词的词语都扫描出来，速度非常快，但是不能解决歧义3、搜索引擎模式：在精确模式下，对长词再次切分，提高召回率，适合用于搜索引擎分词 支持繁体分词 支持自定义词典 算法： 基于前缀词典实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图 (DAG) 采用了动态规划查找最大概率路径, 找出基于词频的最大切分组合 对于未登录词，采用了基于汉字成词能力的 HMM 模型，使用了 Viterbi 算法 用法实例：下面我们通过简单的代码来看一下精确模式、全模式、搜索引擎模式三种分词模式的分词效果。代码如下：1234567891011121314# -*- coding: utf-8 -*-import jiebastring = '话说天下大势，分久必合，合久必分。周末七国分争，并入于秦。及秦灭之后，楚、汉分争，又并入于汉。汉朝自高祖斩白蛇而起义，一统天下，后来光武中兴，传至献帝，遂分为三国。推其致乱之由，殆始于桓、灵二帝。桓帝禁锢善类，崇信宦官。及桓帝崩，灵帝即位，大将军窦武、太傅陈蕃共相辅佐。时有宦官曹节等弄权，窦武、陈蕃谋诛之，机事不密，反为所害，中涓自此愈横。'# 精确模式default_result = jieba.cut(string)print('精确模式：' + '/'.join(default_result))# 全模式full_result = jieba.cut(string, cut_all=True)print('全模式：' + '/'.join(full_result))# 搜索引擎模式search_result = jieba.cut_for_search(string)print('搜索引擎模式：' + '/'.join(search_result)) 结果：12345精确模式：话/说/天下/大势/，/分久必合/，/合久必分/。/周末/七/国/分争/，/并入/于/秦/。/及/秦灭/之后/，/楚/、/汉/分争/，/又/并入/于汉/。/汉朝/自/高祖/斩/白蛇/而/起义/，/一统天下/，/后来/光武/中兴/，/传至/献帝/，/遂/分为/三国/。/推其致/乱/之/由/，/殆/始于/桓/、/灵/二帝/。/桓帝/禁锢/善类/，/崇信/宦官/。/及桓帝/崩/，/灵帝/即位/，/大将军/窦武/、/太傅陈/蕃/共/相/辅佐/。/时有/宦官/曹节/等/弄权/，/窦武/、/陈蕃/谋/诛/之/，/机事不密/，/反为/所害/，/中/涓/自此/愈横/。全模式：话/说/天下/大势///分久必合///合久必分///周末/七国/国分/分争///并入/于/秦///及/秦/灭/之后///楚///汉/分争///又/并入/于/汉///汉朝/自/高祖/斩/白蛇/而/起义///一统/一统天下/天下///后来/光/武/中兴///传/至/献帝///遂/分为/三国///推/其/致/乱/之/由///殆/始于/桓///灵/二帝///桓/帝/禁锢/善类///崇信/宦官///及/桓/帝/崩///灵/帝/即位///大将/大将军/将军/窦/武///太傅/太傅陈/蕃/共相/相辅/辅佐///时/有/宦官/曹/节/等/弄权///窦/武///陈/蕃/谋/诛/之///机事不密///反为/所/害///中/涓/自此/愈/横//搜索引擎模式：话/说/天下/大势/，/分久必合/，/合久必分/。/周末/七/国/分争/，/并入/于/秦/。/及/秦灭/之后/，/楚/、/汉/分争/，/又/并入/于汉/。/汉朝/自/高祖/斩/白蛇/而/起义/，/一统/天下/一统天下/，/后来/光武/中兴/，/传至/献帝/，/遂/分为/三国/。/推其致/乱/之/由/，/殆/始于/桓/、/灵/二帝/。/桓帝/禁锢/善类/，/崇信/宦官/。/及桓帝/崩/，/灵帝/即位/，/大将/将军/大将军/窦武/、/太傅/太傅陈/蕃/共/相/辅佐/。/时有/宦官/曹节/等/弄权/，/窦武/、/陈蕃/谋/诛/之/，/机事不密/，/反为/所害/，/中/涓/自此/愈横/。 从上面的结果来看，分词效果还不错。 jieba还提供了下面几个功能，具体实现代码可以自行到github上查看，这里不再详细介绍。 添加自定义词典：开发者还可以指定自己自定义的词典，以便包含jieba词库中没有的词。 关键词提取： 基于TF-IDF算法的关键词抽取(jieba.analyse) 基于TextRank算法的关键词抽取(jieba.analyse.textrank) THULACTHULAC（THU Lexical Analyzer for Chinese）由清华大学自然语言处理与社会人文计算实验室研制推出的一套中文词法分析工具包，具有中文分词和词性标注功能。 GitHub：https://github.com/thunlp/THULAC-Python 特点THULAC具有如下几个特点： 能力强。利用我们集成的目前世界上规模最大的人工分词和词性标注中文语料库（约含5800万字）训练而成，模型标注能力强大。 准确率高。该工具包在标准数据集Chinese Treebank（CTB5）上分词的F1值可达97.3％，词性标注的F1值可达到92.9％，与该数据集上最好方法效果相当。 速度较快。同时进行分词和词性标注速度为300KB/s，每秒可处理约15万字。只进行分词速度可达到1.3MB/s。 用法实例下面我们开看下THULAC的分词效果，代码如下：123456789101112# -*- coding: utf-8 -*-import thulac# 默认模式，有词性标注thu1 = thulac.thulac()thu1_result = thu1.cut(string, text=True)print('thu1_result：' + thu1_result)# 只分词，不进行词性标注thu2 = thulac.thulac(seg_only=True)thu2_result = thu2.cut(string, text=True)print('thu2_result：' + thu2_result) 分词结果：123thu1_result：话_n 说_v 天下_n 大势_n ，_w 分久必合_id ，_w 合久必分_id 。_w 周末_t 七国分争_id ，_w 并入_v 于_p 秦_g 。_w 及_c 秦灭_v 之后_f ，_w 楚_j 、_w 汉_g 分争_v ，_w 又_c 并入_v 于_p 汉_g 。_w 汉朝_t 自_r 高_a 祖斩_n 白蛇_n 而_c 起义_v ，_w 一统天下_id ，_w 后_f 来_v 光武_ns 中兴_nz ，_w 传_v 至_d 献_v 帝_g ，_w 遂_d 分为_v 三_m 国_n 。_w 推_v 其_r 致乱_v 之_u 由_g ，_w 殆始_v 于_p 桓_g 、_w 灵二帝_id 。_w 桓帝_np 禁锢_v 善类_n ，_w 崇信_v 宦官_n 。_w 及_c 桓帝崩_n ，_w 灵帝_n 即位_n ，_w 大将军_n 窦武_v 、_w 太傅_n 陈蕃_np 共_d 相_d 辅佐_v 。_w 时_g 有_v 宦官_n 曹节_np 等_u 弄权_n ，_w 窦武_np 、_w 陈蕃_np 谋诛_v 之_u ，_w 机事不密_i ，_w 反_d 为_v 所_u 害_v ，_w 中_j 涓_j 自此_d 愈_d 横_a 。_wthu2_result：话 说 天下 大势 ， 分久必合 ， 合久必分 。 周末 七国分争 ， 并入 于 秦 。 及 秦灭 之后 ， 楚 、 汉分 争 ， 又 并入 于汉 。 汉朝 自 高祖斩白蛇而起义 ， 一统天下 ， 后 来 光武 中兴 ， 传 至 献帝 ， 遂 分为 三 国 。 推 其 致乱 之 由 ， 殆始 于 桓 、 灵二帝 。 桓帝 禁锢善类 ， 崇信 宦官 。 及 桓帝崩 ， 灵帝 即位 ， 大将 军窦武 、 太 傅陈蕃 共 相辅佐 。 时 有 宦官 曹节 等 弄权 ， 窦武 、 陈蕃 谋诛之 ， 机事不密 ， 反 为 所 害 ， 中涓 自此 愈横 。 PKUSegPKUSeg是由北京大学语言计算与机器学习研究组研制推出的一套全新的中文分词工具包。它简单易用，支持多领域分词，在不同领域的数据上都大幅提高了分词的准确率。 GitHub: https://github.com/lancopku/pkuseg-python 特点pkuseg有如下几个特点： 多领域分词 更高的分词准确率 支持用户自训练模型 支持词性标注 用法实例分词代码：12345import pkuseg# 使用默认配置进行分词seg = pkuseg.pkuseg()text = seg.cut(string)print(text) 分词结果：1['话说', '天下', '大势', '，', '分久必合', '，', '合久必分', '。', '周末', '七', '国', '分争', '，', '并入', '于', '秦', '。', '及', '秦灭', '之后', '，', '楚', '、', '汉分', '争', '，', '又', '并入', '于汉', '。', '汉朝', '自', '高', '祖斩', '白蛇而起义', '，', '一统天下', '，', '后来', '光武', '中兴', '，', '传至', '献帝', '，', '遂', '分为', '三国', '。', '推', '其', '致乱', '之', '由', '，', '殆始于桓', '、', '灵二帝', '。', '桓帝', '禁锢', '善类', '，', '崇信', '宦官', '。', '及', '桓帝崩', '，', '灵帝', '即位', '，', '大将军', '窦武', '、', '太傅', '陈', '蕃共', '相', '辅佐', '。', '时有', '宦官', '曹节', '等', '弄权', '，', '窦武', '、', '陈', '蕃谋', '诛之', '，', '机事不密', '，', '反为所害', '，', '中', '涓', '自此', '愈', '横', '。'] 三个库比较pkuseg在开源时对其进行测评，pkuseg的作者们选择 THULAC、结巴分词等国内代表分词工具包与 pkuseg 做性能比较。他们选择 Linux 作为测试环境，在新闻数据（MSRA）和混合型文本（CTB8）数据上对不同工具包进行了准确率测试。此外，测试使用的是第二届国际汉语分词评测比赛提供的分词评价脚本。评测结果如下： 我们可以看到，最广泛使用的结巴分词准确率最低，清华的THULAC分词准确率也低于PKUSeg。当然，pkuseg 是在这些数据集上训练的，因此它在这些任务上的准确率也会更高一些，也由此在其开源后对于其高准确率曾引起一些质疑和争议，有兴趣的朋友可以自行百度或点击下面链接查看：https://github.com/lancopku/pkuseg-python/issues/9 更多python中文分词库上面都只是简单介绍了jieba、THULAC和pkuseg三个分词python库，更多用法和参数请到相应的github上查阅。 还有一些中文分词的python库，这里只提供其github地址，就不一一介绍，有兴趣的朋友自行查看研究。 SnowNLP https://github.com/isnowfy/snownlp NLPIR https://github.com/NLPIR-team/NLPIR FoolNLTK https://github.com/rockyzhengwu/FoolNLTK LTP https://github.com/HIT-SCIR/pyltp","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.chenhanpeng.com/categories/机器学习/"}],"tags":[{"name":"中文分词","slug":"中文分词","permalink":"http://www.chenhanpeng.com/tags/中文分词/"}]},{"title":"推荐系统介绍","slug":"推荐系统介绍","date":"2019-04-15T16:29:20.000Z","updated":"2019-06-12T01:20:59.574Z","comments":true,"path":"2019/04/16/推荐系统介绍/","link":"","permalink":"http://www.chenhanpeng.com/2019/04/16/推荐系统介绍/","excerpt":"","text":"一、背景随着互联网的快速发展，我们进入一个信息爆炸的时代。互联网的发展，为我们提供了越来越多的服务平台，比如购物平台、视频播放网站、音乐播放器、社交网婚恋网等等，提供的物品种类也越来越多样。如何更好地满足客户的需求，成了企业的难题。 在这个信息爆炸的时代，无论是消费者还是信息生产者都遇到了很大的挑战：作为消费者，如何从大量信息中找到自己感兴趣的信息是一件非常困难的事情；作为信息生产者，如何让自己生产的信息脱颖而出，受到广大用户的关注，也是一件非常困难的事情。推荐系统就是解决这一矛盾的重要工具。 二、什么是推荐系统推荐系统是一项工程技术解决方案，通过利用机器学习等技术，在用户使用产品进行浏览交互的过程中，系统主动用户展示可能会喜欢的物品，从而促进物品的消费，节省用户时间，提升用户体验，做到资源的优化配置。 要将推荐系统落地到业务上需要大量的工程开发：涉及到日志打点、日志收集、ETL、分布式计算、特征工程、推荐算法建模、数据存储、提供接口服务、UI展示和交互、推荐效果评估等。 推荐系统的本质是在用户需求不明确的情况下，从海量的信息中为用户寻找其感兴趣的信息的技术手段。 推荐系统的任务就是联系用户和信息(物品)，一方面帮助用户发现对自己有价值的信息，另一方面让信息能够展现在对它感兴趣的用户面前，从而实现信息消费者和信息生产者的双赢。 推荐系统很好满足了用户、平台、内容提供商三方的需求。以淘宝为例：用户及在淘宝上购物的买家，平台即淘宝网站，网站上众多的店主就是内容提供方。通过推荐系统可以更好将商品曝光给要购买的用户，提升社会资源的配置效率。 三、推荐系统应用领域推荐系统应用场景正在不断被挖掘和创造，只要存在大量供用户消费的产品，就有推荐系统发挥价值的地方。 推荐系统主要应用的领域有如下几类： 电子商务：淘宝、京东、苏宁易购、亚马逊等 视频：腾讯视频、优酷、抖音等 音乐：网易云音乐、QQ音乐等 生活服务类：美团、携程 资讯类：头条、一点资讯等 社交类：陌陌、珍爱网等 四、常用推荐算法接下来我们简单介绍一些推荐系统常用的算法： 1、基于内容的推荐前面我们提到过推荐系统通过技术将用户和物品关联起来，物品本身包含很多属性，用户通过与物品的交互产生行为日志，这些日志可以作为衡量用户对物品偏好的标签，通过这些标签为用户做推荐，这就是基于内容的推荐算法。以音乐播放器推荐歌曲为例，歌曲有歌名、演唱者、类型、年代等标签信息，假设某个用户经常听张杰的歌，或者用户收藏的歌单中大部分都是张杰的歌曲，那么我们可以根据这些兴趣特征为用户推荐张杰的歌。 2、基于协同过滤的推荐用户与物品的交互留下了用户的标记，我们可以通过“物以类聚，人以群分”的思想为用户提供个性化推荐。 “物以类聚”具体来说就是：如果有许多用户对两个物品有相似的偏好，说明这两个物品是“相似”的，通过推荐与用户喜欢过的物品相似的物品的方法为用户提供个性化推荐，这就是基于物品的协同过滤推荐算法。 “人以群分”简单来说就是：找到与用户兴趣相同的人，将这些兴趣相同的用户浏览过的物品推荐给用户，这就是基于用户的协同过滤推荐算法。 五、推荐系统的价值接下来我们简单介绍一下推荐系统的价值： 从用户角度来说，推荐系统可以让用户快速从海量信息中找到自己感兴趣的物品，节省了用户时间，提升用户的使用体验。从平台角度来看：精准的推荐可以提升用户对平台的粘性，让用户喜欢上平台。平台整体营销收入提升，发现用户更多需求，满足其需求销售更多相关服务，获取更多利润。从内容提供商角度来看，提升物品被卖出去的概率，提升提供商的销量。 文章参考来源：https://mp.weixin.qq.com/s/DofYtvZCe-7RTicLqYtL4A","categories":[{"name":"大数据","slug":"大数据","permalink":"http://www.chenhanpeng.com/categories/大数据/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://www.chenhanpeng.com/tags/大数据/"},{"name":"推荐系统","slug":"推荐系统","permalink":"http://www.chenhanpeng.com/tags/推荐系统/"}]},{"title":"中文分词","slug":"中文分词","date":"2019-04-09T02:52:01.000Z","updated":"2019-04-27T11:53:28.275Z","comments":true,"path":"2019/04/09/中文分词/","link":"","permalink":"http://www.chenhanpeng.com/2019/04/09/中文分词/","excerpt":"","text":"中文分词(Chinese Word Segmentation)：是指将一个汉字序列切分为一个个单独的词。中文分词是中文自然语言处理的一个最基本的环节。中文分词与英文分词有很大的不同，对英文而言，一个单词就是一个词，而汉语是以字为基本的书写单位，词语之间没有明显的区分标记，需要人为切分。 根据中文分词的特点，可以把中文分词算法分为四大类： 基于规则的分词方法 基于统计的分词方法 基于语义的分词方法 基于理解的分词方法 基于规则的分词方法该分词方法又称为机械分词方法、基于字典的分词方法。它是按照一定的策略将待分析的汉字串与一个“充分大的”机器词典中的词条进行匹配。若在词典中找到某个字符串，则匹配成功。 该方法有三个要素：分词词典、文本扫描顺序和匹配原则。文本的扫描顺序有正向扫描、逆向扫描和双向扫描。匹配原则主要有最大匹配、最小匹配、逐词匹配和最佳匹配。 最大匹配法（MM）：基本思想是：假设自动分词词典中的最长词条所含汉字的个数为 i，则取被处理材料当前字符串序列中的前 i 个字符作为匹配字段，查找分词词典，若词典中有这样一个 i 字词，则匹配成功，匹配字段作为一个词被切分出来；若词典中找不到这样的一个 i 字词，则匹配失败，匹配字段去掉最后一个汉字，剩下的字符作为新的匹配字段，再进行匹配，如此进行下去，直到匹配成功为止。 逆向最大匹配法（RMM）：该方法的分词过程与 MM 法相同，不同的是从句子（或文章）末尾开始处理，每次匹配不成功时去掉的是前面的一个汉字。 逐词遍历法：把词典中的词按照由长到短递减的顺序逐字搜索整个待处理的材料，一直到把全部的词切分出来为止。不论分词词典多大，被处理的材料多么小，都得把这个分词词典匹配一遍。 设立切分标志法：切分标志有自然和非自然之分。自然切分标志是指文章中出现的非文字符号，如标点符号等；非自然标志是利用词缀和不构成词的词（包 括单音词、复音节词以及象声词等）。设立切分标志法首先收集众多的切分标志，分词时先找出切分标志，把句子切分为一些较短的字段，再用 MM、RMM 或其它的方法进行细加工。这种方法并非真正意义上的分词方法，只是自动分词的一种前处理方式而已，它要额外消耗时间扫描切分标志，增加存储空间存放那些非 自然切分标志。 最佳匹配法（OM）：此法分为正向的最佳匹配法和逆向的最佳匹配法，其出发点是：在词典中按词频的大小顺序排列词条，以求缩短对分词词典的检索时 间，达到最佳效果，从而降低分词的时间复杂度，加快分词速度。实质上，这种方法也不是一种纯粹意义上的分词方法，它只是一种对分词词典的组织方式。OM 法的分词词典每条词的前面必须有指明长度的数据项，所以其空间复杂度有所增加，对提高分词精度没有影响，分词处理的时间复杂度有所降低。 基于规则的分词方法的优点是简单，易于实现。但缺点有很多：匹配速度慢；存在交集型和组合型歧义切分问题；词本身没有一个标准的定义，没有统一标准的词集；不同词典产生的歧义也不同；缺乏自学习的智能性。 基于统计的分词方法基于统计的分词方法是在给定大量已经分词的文本情况下，利用统计机器学习模型学习词语切分的规律，从而实现对未知文本的切分。 该方法的主要思想：词是稳定的组合，在上下文中，相邻的字同时出现的次数越多，越有可能构成一个词。因此字与字相邻出现的概率能较好反映词的可信度。可以对训练文本中相邻出现的各个字的组合的频度进行统计，计算它们之间的互现信息。互现信息体现了汉字之间结合关系的紧密程度。当紧密程 度高于某一个阈值时，便可以认为此字组可能构成了一个词。该方法又称为无字典分词。 该方法应用的主要统计模型有：N元文法模型(N-gram)、隐马尔科夫模型(Hiden Markov Model, HMM)、最大熵模型(ME)、条件随机场模型(Conditional Random Fields, CRF)等。 在实际的应用中，这种分词方法都需要使用分词词典来进行字符串匹配分词，同时使用统计方法识别一些新词，即将字符串频率统计和字符串匹配结合起来，既发挥匹配分词切分速度快、效率高的特点，又利用了无词典分词结合上下文识别生词、自动消除歧义的优点。 基于语义的分词方法语义分词法引入了语义分析，对自然语言自身的语言信息进行更多的处理，如扩充转移网络法、知识分词语义分析法、邻接约束法、综合匹配法、后缀分词法、特征词库法、矩阵约束法、语法分析法等。 扩充转移网络法：该方法以有限状态机概念为基础。有限状态机只能识别正则语言，对有限状态机作的第一次扩充使其具有递归能力，形成递归转移网络 （RTN）。在RTN 中，弧线上的标志不仅可以是终极符（语言中的单词）或非终极符（词类），还可以调用另外的子网络名字分非终极符（如字或字串的成词条件）。这样，计算机在 运行某个子网络时，就可以调用另外的子网络，还可以递归调用。词法扩充转移网络的使用， 使分词处理和语言理解的句法处理阶段交互成为可能，并且有效地解决了汉语分词的歧义。 矩阵约束法：其基本思想是：先建立一个语法约束矩阵和一个语义约束矩阵， 其中元素分别表明具有某词性的词和具有另一词性的词相邻是否符合语法规则， 属于某语义类的词和属于另一词义类的词相邻是否符合逻辑，机器在切分时以之约束分词结果。 基于理解的分词方法基于理解的分词方法是通过让计算机模拟人对句子的理解，达到识别词的效果。其基本思想就是在分词的同时进行句法、语义分析，利用句法信息和语义信息来处理歧义现象。它通常包括三个部分：分词子系统、句法语义子系统、总控部分。在总控部分的协调下，分词子系统可以获得有关词、句子等的句法和语义信息来对分词歧义进行判断，即它模拟了人对句子的理解过程。这种分词方法需要使用大量的语言知识和信息。目前基于理解的分词方法主要有专家系统分词法和神经网络分词法等。 专家系统分词法：从专家系统角度把分词的知识（包括常识性分词知识与消除歧义切分的启发性知识即歧义切分规则）从实现分词过程的推理机中独立出来，使知识库的维护与推理机的实现互不干扰，从而使知识库易于维护和管理。它还具有发现交集歧义字段和多义组合歧义字段的能力和一定的自学习功能。 神经网络分词法：该方法是模拟人脑并行，分布处理和建立数值计算模型工作的。它将分词知识所分散隐式的方法存入神经网络内部，通过自学习和训练修改内部权值，以达到正确的分词结果，最后给出神经网络自动分词结果，如使用 LSTM、GRU 等神经网络模型等。 神经网络专家系统集成式分词法：该方法首先启动神经网络进行分词，当神经网络对新出现的词不能给出准确切分时，激活专家系统进行分析判断，依据知识库进行推理，得出初步分析，并启动学习机制对神经网络进行训练。该方法可以较充分发挥神经网络与专家系统二者优势，进一步提高分词效率。 参考来源：https://cuiqingcai.com/5844.html","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.chenhanpeng.com/categories/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.chenhanpeng.com/tags/机器学习/"},{"name":"中文分词","slug":"中文分词","permalink":"http://www.chenhanpeng.com/tags/中文分词/"}]},{"title":"文本挖掘预处理之TF-IDF","slug":"TF-IDF-1","date":"2019-03-25T14:10:10.000Z","updated":"2019-04-27T11:53:19.381Z","comments":true,"path":"2019/03/25/TF-IDF-1/","link":"","permalink":"http://www.chenhanpeng.com/2019/03/25/TF-IDF-1/","excerpt":"","text":"TF-IDF（Term Frequency-Inverse Document Frequency）即“词频-反文档频率”，主要由TF和IDF两部分组成。TF-IDF是一种用于资讯检索与资讯探勘的常用加权技术，是一种统计方法，用于评估一个词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要程度与它在文件中出现的次数成正比，但同时与它在语料库中出现的频率成反比。 TF——词频：一个词在文章中出现的次数。 在计算词频时，需要注意停用词的过滤。什么是停用词：在文章中出现次数最多的“的”、“是”、“在”等最常用词，但对结果毫无帮助，必须过滤的词。 TF计算有两种方式，具体公式如下： IDF——反文档频率：一个词在所有文章中出现的频率。如果包含这个词的文章越少，IDF越大，则说明词具有很好的类别区分能力。计算公式如下： 将TF和IDF相乘，就得到一个词的TF-IDF值，某个词对文章的重要性越高，该值越大，于是排在前面的几个词，就是这篇文章的关键词。 TF-IDF总结：优点：简单快速，结果比较符合实际情况。 缺点：单纯以“词频”做衡量标准，不够全面，有时重要的词可能出现的次数不多。 用python实现TF-IDF的计算将下图所示的已经分好词的文章作为语料库，计算101it.seg.cln.txt中的TF-IDF。 具体python代码实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172# -*- coding: utf-8 -*-import osimport math # 要计算TF-IDF的文章路径file_path = './data/101it.seg.cln.txt'# 语料库目录路径data_dir_path = './data' # 获取文章内容def read_content(file): content = open(file, 'r', encoding='UTF-8') return content # 计算IDFdef calculate_idf(dir_path): all_word_set = set() article_list = [] article_count = 0 for fd in os.listdir(dir_path): article_count += 1 file = dir_path + '/' + fd content = read_content(file) content_set = set() for line in content: word_tmp = line.strip().split(' ') for word in word_tmp: word = word.strip() all_word_set.add(word) content_set.add(word) article_list.append(content_set) idf_dict = &#123;&#125; for word in all_word_set: count = 0 for article in article_list: if word in article: count += 1 idf_dict[word] = math.log(float(article_count)/(float(count) + 1.0)) return idf_dict # 计算TFdef calculate_tf(file): content = read_content(file) word_set = set() word_dict = &#123;&#125; word_count = 0 # 计算词频和文章总词数 for line in content: word_tmp = line.strip().split(' ') for word in word_tmp: word = word.strip() if word not in word_dict: word_dict[word] = 1 else: word_dict[word] += 1 word_count += 1 word_set.add(word) # 计算TF for tmp in word_set: word_dict[tmp] = float(word_dict[tmp])/float(word_count) return word_dict if __name__ == \"__main__\": idf_dict = calculate_idf(data_dir_path) tf_dict = calculate_tf(file_path) tfidf_dict = &#123;&#125; for key in tf_dict: tfidf_dict[key] = tf_dict[key] * idf_dict[key] print(tfidf_dict) TF-IDF应用：TF-IDF有下面几个应用，具体的实现后续文章再给大家介绍： 提取文章的关键词 TF-IDF结合余弦相似度找相似文章 给文章自动生成摘要","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.chenhanpeng.com/categories/机器学习/"}],"tags":[{"name":"TF-IDF","slug":"TF-IDF","permalink":"http://www.chenhanpeng.com/tags/TF-IDF/"}]},{"title":"K-近邻(KNN)算法","slug":"knn","date":"2019-03-21T09:04:17.000Z","updated":"2019-04-27T11:53:09.722Z","comments":true,"path":"2019/03/21/knn/","link":"","permalink":"http://www.chenhanpeng.com/2019/03/21/knn/","excerpt":"","text":"K-近邻（KNN，K-Nearest Neighbor）算法是一种基本分类与回归方法，在机器学习分类算法中占有相当大的地位，既是最简单的机器学习算法之一，也是基于实例的学习方法中最基本的，又是最好的文本分类算法之一。 我们本篇文章只讨论分类问题的KNN算法。 KNN算法概述KNN是通过测量不同特征值之间的距离进行分类。 KNN算法思路：如果一个样本在特征空间中的k各最相似（即特征空间中最近邻）的样本中的大多数属于某一个类别，则该样本也属于该类别。其中k一个是不大于20的整数。KNN算法中，所选择的邻居都是已经正确分类的对象。 KNN算法的输入为实例的特征向量，对应于特征空间的点；输出为实例的类别，可以取多类。 KNN算法实际上利用训练数据集对特征向量空间进行划分，并作为其分类的模型。k值的选择、距离度量和分类决策规则是KNN算法的三个基本要素。 KNN算法工作原理KNN算法工作原理可描述为：1、假设有一个带有标签的训练样本集，其中包含每条数据与所属分类的对应关系。 2、输入没有带标签的新数据后，计算新数据与训练样本集中每条数据的距离。 3、对求得的所有距离进行升序排序。 4、选取k个与新数据距离最小的训练数据。 5、确定k个训练数据所在类别出现的频率。 6、返回k个训练数据中出现频率最高的类别作为新数据的分类。 KNN算法距离计算方式在KNN中，通过计算对象间距离来作为各个对象之间的相似性指标，这里的距离计算一般采用欧式距离或者是曼哈顿距离，两种距离的计算公式如下图所示： KNN算法特点： 优点：精度高、对异常值不敏感、无数据输入假定 缺点：计算复杂度高、空间复杂度高 适用数据范围：数值型和标称型 KNN算法demo实例python（python3.6）实现一个KNN算法的简单demo 12345678910111213141516171819202122232425262728# -*- coding: utf-8 -*-import numpy as npfrom collections import Counterimport os # 创建样本数据集def createDataSet(): group = np.array([[1.0, 1.1], [1.0, 1.0], [0, 0.1], [0.1, 0]]) labels = ['A', 'A', 'B', 'B'] return group, labels # 近邻算法def classify0 (inX, dataSet, labels, k): diffMat = np.tile(inX,(dataSet.shape[0],1)) - dataSet #待分类的输入向量与每个训练数据做差 distance = ((diffMat ** 2).sum(axis=1)) ** 0.5 #欧氏距离 sortDistanceIndices = distance.argsort() #从小到大的顺序，返回对应索引值 votelabel = [] for i in range(k): votelabel.append(labels[sortDistanceIndices[i]]) Xlabel = Counter(votelabel).most_common(1) return Xlabel[0][0] if __name__ == \"__main__\": # # 创建数据集和 k-近邻算法 group, labels = createDataSet() # 新数据为[0, 0], k=3 label = classify0([0, 0], group, labels, 3) print(label) 执行上面代码，在控制台打印输出 B，即为数据[0, 0]的分类。 方法说明上面python代码中有几个方法在这里简单说明一下： Counter(votelabel).most_common(1)：求votelabel中出现次数最多的元素 np.tile(A,B)：若B为int型：在列方向上将A重复B次 若B为元组(m,n):将A在列方向上重复n次，在行方向上重复m次 sum(axis=1)：函数的axis参数，axis=0:按列相加；axis=1:按行的方向相加，即每行数据求和 argsort：将数组的值按从小到大排序后，输出索引值","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.chenhanpeng.com/categories/机器学习/"}],"tags":[{"name":"KNN","slug":"KNN","permalink":"http://www.chenhanpeng.com/tags/KNN/"},{"name":"机器学习","slug":"机器学习","permalink":"http://www.chenhanpeng.com/tags/机器学习/"},{"name":"分类算法","slug":"分类算法","permalink":"http://www.chenhanpeng.com/tags/分类算法/"}]}]}